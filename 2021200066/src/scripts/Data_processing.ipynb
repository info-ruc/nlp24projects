{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13b78fd8-a921-4129-b9cc-3c0cf2887c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import math\n",
    "import nltk\n",
    "import time\n",
    "import jieba\n",
    "import torch\n",
    "import pickle\n",
    "import zipfile\n",
    "import warnings\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import streamlit as st\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sentence_transformers.util import cos_sim \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering, BertModel\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from wordcloud import WordCloud,STOPWORDS,ImageColorGenerator\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef3873a5-d660-4ae2-9b0e-49168201667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_beijing = pd.read_excel(r'../dataset/xiecheng_beijing_comment.xlsx').astype(str)\n",
    "pd_guangzhou = pd.read_excel(r'../dataset/xiecheng_guangzhou_comment.xlsx').astype(str)\n",
    "pd_shanghai = pd.read_excel(r'../dataset/xiecheng_shanghai_comment.xlsx').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cc0e6c-cdd6-43e9-b55b-edbf7034ddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#展示信息\n",
    "print('评论数目（北京）：%d' % pd_beijing.shape[0])\n",
    "print('评论数目（广州）：%d' % pd_guangzhou.shape[0])\n",
    "print('评论数目（上海）：%d' % pd_shanghai.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea32186-e82f-4b37-9776-3753da55f6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#调整格式\n",
    "pd_beijing = pd_beijing.rename(columns={'酒店名字': 'name', '酒店分类': 'class','酒店位置': 'location','住客点评': 'total', 'Unnamed: 6': 'loc', 'Unnamed: 7': 'fac', 'Unnamed: 8': 'ser', 'Unnamed: 9': 'hyg'})\n",
    "pd_guangzhou = pd_guangzhou.rename(columns={'酒店名字': 'name', '酒店分类': 'class','酒店位置': 'location','住客点评': 'total', 'Unnamed: 6': 'loc', 'Unnamed: 7': 'fac', 'Unnamed: 8': 'ser', 'Unnamed: 9': 'hyg'})\n",
    "pd_shanghai = pd_shanghai.rename(columns={'酒店名字': 'name', '酒店分类': 'class','酒店位置': 'location','住客点评': 'total', 'Unnamed: 6': 'loc', 'Unnamed: 7': 'fac', 'Unnamed: 8': 'ser', 'Unnamed: 9': 'hyg'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357a3040-de0c-4e78-8fa8-cb73662c6219",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_beijing = pd_beijing.drop(index=0)\n",
    "pd_guangzhou = pd_guangzhou.drop(index=0)\n",
    "pd_shanghai = pd_shanghai.drop(index=0)\n",
    "#除去空行\n",
    "pd_beijing.dropna(inplace=True)\n",
    "pd_guangzhou.dropna(inplace=True)\n",
    "pd_shanghai.dropna(inplace=True)\n",
    "#将所有字符全部变为小写形式\n",
    "pd_beijing['review']=pd_beijing['review'].str.lower()\n",
    "pd_guangzhou['review']=pd_guangzhou['review'].str.lower()\n",
    "pd_shanghai['review']=pd_shanghai['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c270205-4e78-4301-95fd-0e30afc1bdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除表情符号的函数\n",
    "def remove_emojis(text):\n",
    "    return re.sub(r'[^\\w\\s，。（）]', '', text)  # 保留字母、数字、空格和中文标点符号\n",
    "\n",
    "pd_beijing['review'] = pd_beijing['review'].apply(remove_emojis)\n",
    "pd_guangzhou['review'] = pd_guangzhou['review'].apply(remove_emojis)\n",
    "pd_shanghai['review'] = pd_shanghai['review'].apply(remove_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35c0b15-fc33-4b15-bf1b-5e2317dca9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将文本中特殊字符替换为空格\n",
    "for ch in '“”‘’：；/？！·~、【】!\"#$%&*+,-./:;<=>?@[\\\\]^_\\'{|};~\\n':\n",
    "    pd_beijing['review'] = pd_beijing['review'].str.replace(ch, \" \")\n",
    "    pd_guangzhou['review'] = pd_guangzhou['review'].str.replace(ch, \" \")\n",
    "    pd_shanghai['review'] = pd_shanghai['review'].str.replace(ch, \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd702cb4-8c89-4dae-a034-a139d278f49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割文本\n",
    "text_column = 'review'\n",
    "def split_text(text):\n",
    "    sentences = []\n",
    "    current_sentence = ''\n",
    "    number_start = True\n",
    "    for char in text:\n",
    "        if char == '（' :\n",
    "            if current_sentence != '':\n",
    "                sentences.append(current_sentence.strip())\n",
    "                current_sentence = ''\n",
    "            number_start = True\n",
    "        elif char.isdigit() and number_start:\n",
    "            continue\n",
    "        elif char == '）' and number_start:\n",
    "            number_start = False\n",
    "        else:\n",
    "            current_sentence += char\n",
    "    if current_sentence.strip() != '':\n",
    "        sentences.append(current_sentence.strip())\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c290ecd5-8498-447b-957b-4d17aff7e3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个新的空列来存储分割后的句子\n",
    "new_columns = [f'Sentence_{i+1}' for i in range(15)]  # 假设最多有10个句子\n",
    "for col in new_columns:\n",
    "    pd_beijing[col] = ''\n",
    "    pd_guangzhou[col] = ''\n",
    "    pd_shanghai[col] = ''\n",
    "\n",
    "def split_text_into_columns(df):\n",
    "    for index, row in df.iterrows():\n",
    "        sentences = split_text(row[text_column])\n",
    "        for i, sentence in enumerate(sentences):\n",
    "            if i < len(new_columns):\n",
    "                df.at[index, new_columns[i]] = sentence\n",
    "    return df\n",
    "pd_beijing = split_text_into_columns(pd_beijing)\n",
    "pd_guangzhou = split_text_into_columns(pd_guangzhou)\n",
    "pd_shanghai = split_text_into_columns(pd_shanghai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd69df9-9230-421f-ab21-eca867c33f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#先将每个评论单独挑出\n",
    "def process_reviews(df):\n",
    "    id_vars = [\"id\", \"name\", \"class\", \"location\", \"review\", \"total\", \"loc\", \"fac\", \"ser\", \"hyg\"]\n",
    "    value_vars = [\n",
    "        \"Sentence_1\", \"Sentence_2\", \"Sentence_3\", \"Sentence_4\", \"Sentence_5\",\n",
    "        \"Sentence_6\", \"Sentence_7\", \"Sentence_8\", \"Sentence_9\", \"Sentence_10\",\n",
    "        \"Sentence_11\", \"Sentence_12\", \"Sentence_13\", \"Sentence_14\", \"Sentence_15\"\n",
    "    ]\n",
    "    df_melted = df.melt(\n",
    "        id_vars=id_vars,\n",
    "        value_vars=value_vars,\n",
    "        var_name=\"review_col\",\n",
    "        value_name=\"reviews\"\n",
    "    )\n",
    "    df_melted = df_melted[df_melted['reviews'] != \"\"]\n",
    "    \n",
    "    return df_melted\n",
    "pd_beijing_reviews = process_reviews(pd_beijing)\n",
    "pd_guangzhou_reviews = process_reviews(pd_guangzhou)\n",
    "pd_shanghai_reviews = process_reviews(pd_shanghai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc75ca4-769d-4284-a45d-34b0a0d50a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将每个评论的每句话截取出来\n",
    "def split_reviews_by_sentence(df):\n",
    "    expanded_rows = []\n",
    "    for index, row in df.iterrows():\n",
    "        review = row['reviews']\n",
    "        sentences = re.split(r'。', review)\n",
    "        for sentence in sentences:\n",
    "            new_row = row.to_dict()\n",
    "            new_row['reviews'] = sentence.strip() \n",
    "            expanded_rows.append(new_row) \n",
    "    expanded_df = pd.DataFrame(expanded_rows)\n",
    "    expanded_df = expanded_df[expanded_df['reviews'] != \"\"]\n",
    "    return expanded_df\n",
    "    \n",
    "pd_beijing_reviews_expanded = split_reviews_by_sentence(pd_beijing_reviews)\n",
    "pd_guangzhou_reviews_expanded = split_reviews_by_sentence(pd_guangzhou_reviews)\n",
    "pd_shanghai_reviews_expanded = split_reviews_by_sentence(pd_shanghai_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908f5576-f99a-4422-96e1-775a6eb0dc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_beijing_reviews_expanded['text_length'] = pd_beijing_reviews_expanded['reviews'].apply(len)\n",
    "pd_guangzhou_reviews_expanded['text_length'] = pd_guangzhou_reviews_expanded['reviews'].apply(len)\n",
    "pd_shanghai_reviews_expanded['text_length'] = pd_shanghai_reviews_expanded['reviews'].apply(len)\n",
    "\n",
    "pd_beijing_reviews_expanded = pd_beijing_reviews_expanded[pd_beijing_reviews_expanded['text_length'] <= 30]\n",
    "pd_guangzhou_reviews_expanded = pd_guangzhou_reviews_expanded[pd_guangzhou_reviews_expanded['text_length'] <= 30]\n",
    "pd_shanghai_reviews_expanded = pd_shanghai_reviews_expanded[pd_shanghai_reviews_expanded['text_length'] <= 30]\n",
    "\n",
    "pd_beijing_reviews_expanded = pd_beijing_reviews_expanded[pd_beijing_reviews_expanded['text_length'] > 4]\n",
    "pd_guangzhou_reviews_expanded = pd_guangzhou_reviews_expanded[pd_guangzhou_reviews_expanded['text_length'] > 4]\n",
    "pd_shanghai_reviews_expanded = pd_shanghai_reviews_expanded[pd_shanghai_reviews_expanded['text_length'] > 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1568f6be-0f4c-4000-9200-44a4c4fa130d",
   "metadata": {},
   "source": [
    "# 分类标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdc7ef5-ff51-4a1b-9626-c123b14aa0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义维度及关键词\n",
    "label_mapping = {'位置': 0, '设施': 1, '服务': 2, '卫生': 3, '其他': 4}\n",
    "dimension_keywords = {\n",
    "    \"位置\": [\"位置\", \"交通\", \"地铁\", \"机场\", \"周边\", \"近\", \"距离\", \"景点\", \"出行\", \"便利\", \"远\", \"步行\", \"火车\", \"机场\", \"周围\", \"边上\", \"地段\", \n",
    "           \"肯德基\", \"全聚德\", \"麦当劳\", \"商城\", \"商务区\", \"对面\", \"庆丰\", \"旁边\", \"颐和园\", \"紧邻\", \"超市\", \"走路\", \"胡同\", \"小区\", \"号线\", \"直行\", \n",
    "           \"博物馆\", \"景点\", \"天安门\", \"走着\", \"购物\", \"公交\", \"偏僻\", \"街\", \"西站\", \"南站\", \"北站\", \"打车\", \"海景\", \"逛街\", \"尖沙咀\", \"中环\",\n",
    "           \"烟花\", \"王府井\", \"国贸\", \"街角\", \"星巴克\", \"巴士\", \"自行车\", \"单车\"],\n",
    "    \"设施\": [\"设施\", \"设备\", \"齐全\", \"装修\", \"条件\", \"冰箱\", \"墙\", \"床\", \"窗\", \"健身房\", \"灯\", \"淋\", \"平方\", \"空调\", \"暖气\", \"电\", \"隔音\",\"安静\", \n",
    "          \"舒适\", \"噪音\", \"热水\", \"车位\", \"隔壁\", \"安检\", \"门禁\", \"浴\", \"沙发\", \"泳\", \"车位\", \"地漏\", \"旧\", \"洗漱\", \"阳台\", \"布局\", \"内部\", \"插座\", \n",
    "           \"家具\", \"停车\", \"室内\", \"精致\", \"停水\", \"加湿器\", \"智能\", \"咖啡机\", \"不热\", \"洗澡\", \"纸巾\", \"音箱\", \"视野\", \"信号\",\"吹风筒\", \"香皂\", \"梳子\", \"写字台\"\n",
    "          \"花潵\", \"花洒\", \"灭火\", \"安全\", \"房卡\", \"硬件\", \"很大\", \"较大\", \"很小\", \"气派\", \"奢华\", \"温泉\", \"较小\", \"日常用品\", \"网络\", \"无线网\",\"卡顿\", \n",
    "          \"衣柜\", \"水壶\", \"空间\", \"凉快\", \"院子\", \"牙膏\", \"护发素\", \"透气\", \"闷\", \"干湿\", \"宽敞\", \"暖和\", \"齐备\", \"马桶\", \"暖风\", \"走廊\", \"物件\",\"太小\", \n",
    "          \"明亮\", \"wifi\", \"网线\", \"枕头\", \"挺大\", \"采光\", \"平米\", \"洗衣\", \"烘干\", \"有点小\", \"地毯\", \"地板\", \"破损\", \"温度\", \"略小\", \"温馨\", \"排气扇\", \"usb\",\n",
    "          \"房间小\", \"贵族\", \"套房\", \"观景台\", \"牙刷\", \"吹风机\", \"插头\", \"被子\", \"毯子\", \"有点小\", \"大小\", \"桌\", \"椅\", \"厨房\", \"单间\", \"光线\", \"维修\", \"简易\"],\n",
    "    \"服务\": [\"服务\", \"态度\", \"员工\", \"前台\", \"餐\", \"热情\", \"耐心\", \"勤务\", \"退房\", \"行李\", \"和气\", \"管理\", \"规范\", \"接待\", \"办理\", \"客气\", \n",
    "          \"免费\", \"升级\", \"上菜\", \"工作人员\", \"死板\", \"指导\", \"早点\", \"姑娘\", \"小哥\", \"小伙\", \"大姐\", \"赠饮\", \"赠送\", \"经理\", \"认真\", \"帮忙\", \"礼貌\",\n",
    "          \"接送\", \"早饭\", \"保安\"],\n",
    "    \"卫生\": [\"卫生\", \"干净\", \"洁\", \"异味\", \"灰尘\", \"臭\", \"味道很大\", \"烟味\", \"浴巾\", \"脏\", \"锈\", \"层灰\", \"毛发\", \"异味\", \"厚灰\",\"污\", \"垃圾\", \n",
    "           \"血\", \"味道大\", \"汗味\", \"毛巾\", \"霉味\", \"难闻\", \"清扫\", \"下水道\", \"熏晕\", \"打扫\", \"粪便\", \"潮湿\", \"拖鞋\", \"垢\"]}\n",
    "\n",
    "def classify_comment(comment):\n",
    "    for dimension, keywords in dimension_keywords.items():\n",
    "        if any(keyword in comment for keyword in keywords):\n",
    "            return dimension\n",
    "    return \"其他\" \n",
    "\n",
    "pd_beijing_reviews_expanded['dimension'] = pd_beijing_reviews_expanded['reviews'].apply(classify_comment)\n",
    "pd_guangzhou_reviews_expanded['dimension'] = pd_guangzhou_reviews_expanded['reviews'].apply(classify_comment)\n",
    "pd_shanghai_reviews_expanded['dimension'] = pd_shanghai_reviews_expanded['reviews'].apply(classify_comment)\n",
    "pd_beijing_reviews_expanded['label'] = pd_beijing_reviews_expanded['dimension'].map(label_mapping)\n",
    "pd_guangzhou_reviews_expanded['label'] = pd_guangzhou_reviews_expanded['dimension'].map(label_mapping)\n",
    "pd_shanghai_reviews_expanded['label'] = pd_shanghai_reviews_expanded['dimension'].map(label_mapping)\n",
    "\n",
    "pd_beijing_reviews_expanded_clean = pd_beijing_reviews_expanded[pd_beijing_reviews_expanded['label'] != 4]\n",
    "pd_guangzhou_reviews_expanded_clean = pd_guangzhou_reviews_expanded[pd_guangzhou_reviews_expanded['label'] != 4]\n",
    "pd_shanghai_reviews_expanded_clean = pd_shanghai_reviews_expanded[pd_shanghai_reviews_expanded['label'] != 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6698c09c-b8d7-47f6-96be-2ec39c294d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "com_df = pd.concat([\n",
    "    pd_beijing_reviews_expanded_clean\n",
    "    pd_chongqing_reviews_expanded_clean,\n",
    "    pd_shanghai_reviews_expanded_clean\n",
    "])\n",
    "com_df.to_excel('../dataset/xiecheng/all_1215.xlsx') \n",
    "pd_beijing_reviews_expanded.to_excel('../dataset/xiecheng/beijing_1215.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4094c2-efba-4fcf-87ca-a7f4008421f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "com_df_01 = com_df[(com_df['label'] == 1) | (com_df['label'] == 0)]\n",
    "com_df_02 = com_df[(com_df['label'] == 2) | (com_df['label'] == 0)]\n",
    "com_df_03 = com_df[(com_df['label'] == 3) | (com_df['label'] == 0)]\n",
    "com_df_12 = com_df[(com_df['label'] == 2) | (com_df['label'] == 1)]\n",
    "com_df_13 = com_df[(com_df['label'] == 3) | (com_df['label'] == 1)]\n",
    "com_df_23 = com_df[(com_df['label'] == 2) | (com_df['label'] == 3)]\n",
    "com_df_01.to_excel('../dataset/xiecheng/all_01_1215.xlsx') \n",
    "com_df_02.to_excel('../dataset/xiecheng/all_02_1215.xlsx') \n",
    "com_df_03.to_excel('../dataset/xiecheng/all_03_1215.xlsx') \n",
    "com_df_12.to_excel('../dataset/xiecheng/all_12_1215.xlsx') \n",
    "com_df_13.to_excel('../dataset/xiecheng/all_13_1215.xlsx') \n",
    "com_df_23.to_excel('../dataset/xiecheng/all_23_1215.xlsx') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866b9bbb-6914-4f17-9402-a8950c776040",
   "metadata": {},
   "source": [
    "# 提前计算文本嵌入embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1689e99-6d3a-4955-9ebc-698a9d8ffdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "comments = com_df_01[\"reviews\"].tolist()#\n",
    "model = AutoModel.from_pretrained('../dataset/mac_1213')\n",
    "tokenizer = AutoTokenizer.from_pretrained('../dataset/mac_1213')\n",
    "# 第一次运行时保存评论嵌入\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# 定义批量处理函数\n",
    "def get_batch_embeddings(sentences, tokenizer, model, batch_size=32):\n",
    "    embeddings_list = []\n",
    "    data_loader = DataLoader(sentences, batch_size=batch_size, shuffle=False)\n",
    "    for batch in tqdm(data_loader, desc=\"Processing batches\"):\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        inputs = {key: val.to(model.device) for key, val in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "        embeddings_list.append(embeddings)\n",
    "    return torch.cat(embeddings_list)\n",
    "\n",
    "# 分批计算嵌入\n",
    "model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 32  # 根据内存大小调整批量大小\n",
    "comment_embeddings = get_batch_embeddings(comments, tokenizer, model, batch_size=batch_size)\n",
    "\n",
    "# 保存嵌入\n",
    "with open(\"./comment_embeddings_mac01.pkl\", \"wb\") as f:\n",
    "    pickle.dump(comment_embeddings.cpu(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a347536b-6232-4e28-a966-cee700b12aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "comments = com_df_02[\"reviews\"].tolist()#\n",
    "model = AutoModel.from_pretrained('../dataset/mac_1213')\n",
    "tokenizer = AutoTokenizer.from_pretrained('../dataset/mac_1213')\n",
    "# 第一次运行时保存评论嵌入\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# 定义批量处理函数\n",
    "def get_batch_embeddings(sentences, tokenizer, model, batch_size=32):\n",
    "    embeddings_list = []\n",
    "    data_loader = DataLoader(sentences, batch_size=batch_size, shuffle=False)\n",
    "    for batch in tqdm(data_loader, desc=\"Processing batches\"):\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        inputs = {key: val.to(model.device) for key, val in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "        embeddings_list.append(embeddings)\n",
    "    return torch.cat(embeddings_list)\n",
    "\n",
    "# 分批计算嵌入\n",
    "model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 32  # 根据内存大小调整批量大小\n",
    "comment_embeddings = get_batch_embeddings(comments, tokenizer, model, batch_size=batch_size)\n",
    "\n",
    "# 保存嵌入\n",
    "with open(\"./comment_embeddings_mac02.pkl\", \"wb\") as f:\n",
    "    pickle.dump(comment_embeddings.cpu(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867230da-28eb-43a3-a66e-8b49c0f8466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "comments = com_df_03[\"reviews\"].tolist()#\n",
    "model = AutoModel.from_pretrained('../dataset/mac_1213')\n",
    "tokenizer = AutoTokenizer.from_pretrained('../dataset/mac_1213')\n",
    "# 第一次运行时保存评论嵌入\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# 定义批量处理函数\n",
    "def get_batch_embeddings(sentences, tokenizer, model, batch_size=32):\n",
    "    embeddings_list = []\n",
    "    data_loader = DataLoader(sentences, batch_size=batch_size, shuffle=False)\n",
    "    for batch in tqdm(data_loader, desc=\"Processing batches\"):\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        inputs = {key: val.to(model.device) for key, val in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "        embeddings_list.append(embeddings)\n",
    "    return torch.cat(embeddings_list)\n",
    "\n",
    "# 分批计算嵌入\n",
    "model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 32  # 根据内存大小调整批量大小\n",
    "comment_embeddings = get_batch_embeddings(comments, tokenizer, model, batch_size=batch_size)\n",
    "\n",
    "# 保存嵌入\n",
    "with open(\"./comment_embeddings_mac03.pkl\", \"wb\") as f:\n",
    "    pickle.dump(comment_embeddings.cpu(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25eb69e6-7561-4679-8ba4-5d0697322b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "comments = com_df_12[\"reviews\"].tolist()#\n",
    "model = AutoModel.from_pretrained('../dataset/mac_1213')\n",
    "tokenizer = AutoTokenizer.from_pretrained('../dataset/mac_1213')\n",
    "# 第一次运行时保存评论嵌入\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# 定义批量处理函数\n",
    "def get_batch_embeddings(sentences, tokenizer, model, batch_size=32):\n",
    "    embeddings_list = []\n",
    "    data_loader = DataLoader(sentences, batch_size=batch_size, shuffle=False)\n",
    "    for batch in tqdm(data_loader, desc=\"Processing batches\"):\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        inputs = {key: val.to(model.device) for key, val in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "        embeddings_list.append(embeddings)\n",
    "    return torch.cat(embeddings_list)\n",
    "\n",
    "# 分批计算嵌入\n",
    "model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 32  # 根据内存大小调整批量大小\n",
    "comment_embeddings = get_batch_embeddings(comments, tokenizer, model, batch_size=batch_size)\n",
    "\n",
    "# 保存嵌入\n",
    "with open(\"./comment_embeddings_mac12.pkl\", \"wb\") as f:\n",
    "    pickle.dump(comment_embeddings.cpu(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa7d5e6-5a25-4d1e-94c3-f2e40b8ca2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "comments = com_df_13[\"reviews\"].tolist()#\n",
    "model = AutoModel.from_pretrained('../dataset/mac_1213')\n",
    "tokenizer = AutoTokenizer.from_pretrained('../dataset/mac_1213')\n",
    "# 第一次运行时保存评论嵌入\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# 定义批量处理函数\n",
    "def get_batch_embeddings(sentences, tokenizer, model, batch_size=32):\n",
    "    embeddings_list = []\n",
    "    data_loader = DataLoader(sentences, batch_size=batch_size, shuffle=False)\n",
    "    for batch in tqdm(data_loader, desc=\"Processing batches\"):\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        inputs = {key: val.to(model.device) for key, val in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "        embeddings_list.append(embeddings)\n",
    "    return torch.cat(embeddings_list)\n",
    "\n",
    "# 分批计算嵌入\n",
    "model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 32  # 根据内存大小调整批量大小\n",
    "comment_embeddings = get_batch_embeddings(comments, tokenizer, model, batch_size=batch_size)\n",
    "\n",
    "# 保存嵌入\n",
    "with open(\"./comment_embeddings_mac13.pkl\", \"wb\") as f:\n",
    "    pickle.dump(comment_embeddings.cpu(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dca4e46-d1be-4b4c-9ef2-7478def89fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "comments = com_df_23[\"reviews\"].tolist()#\n",
    "model = AutoModel.from_pretrained('../dataset/mac_1213')\n",
    "tokenizer = AutoTokenizer.from_pretrained('../dataset/mac_1213')\n",
    "# 第一次运行时保存评论嵌入\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# 定义批量处理函数\n",
    "def get_batch_embeddings(sentences, tokenizer, model, batch_size=32):\n",
    "    embeddings_list = []\n",
    "    data_loader = DataLoader(sentences, batch_size=batch_size, shuffle=False)\n",
    "    for batch in tqdm(data_loader, desc=\"Processing batches\"):\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        inputs = {key: val.to(model.device) for key, val in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "        embeddings_list.append(embeddings)\n",
    "    return torch.cat(embeddings_list)\n",
    "\n",
    "# 分批计算嵌入\n",
    "model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 32  # 根据内存大小调整批量大小\n",
    "comment_embeddings = get_batch_embeddings(comments, tokenizer, model, batch_size=batch_size)\n",
    "\n",
    "# 保存嵌入\n",
    "with open(\"./comment_embeddings_mac23.pkl\", \"wb\") as f:\n",
    "    pickle.dump(comment_embeddings.cpu(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6bb784-5b56-47be-b9fe-6dd3cfef83e8",
   "metadata": {},
   "source": [
    "# 情感标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab04dbe-0854-4504-bbd1-2632fc87f0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印相似度和评论相关信息\n",
    "positive_words = [\"干净\", \"整洁\", \"清爽\", \"卫生良好\", \"没有异味\", \"没有味道\", \"表扬\", \"非常好\", \"没任何异味\", \"虽然不大\", \"虽然小\", \"虽然没电梯\", \"没有噪音\", \n",
    "                 \"但也\", \"不远\", \"不吵\", \"不费劲\", \"没有很重\", \"不差\", \"不算差\", \"没什么缺点\", \"没啥缺点\", \"没缺点\", \"灿烂\", \"无破损\", \"不错\", \"齐全\", \"出差\", \n",
    "                  \"没有什么异味\", \"没异味\", \"不坏\", \"不会感觉潮湿\", \"不小\", \"没有味道\", \"没味道\", \"无异味\", \"挺大的\", '够大', \"床还是挺舒服的\", \"感觉很好\", \n",
    "                 \"离南站不太远\"]\n",
    "negative_words = [\"脏\", \"不干净\", \"不卫生\", \"恶心\", \"乱\", \"不建议\", \"不喜欢\", \"讨厌\", \"不推荐\", \"不太喜欢\", \"异味重\", \"不好\", \"狭小\", \n",
    "                  \"没希望\", \"别扭\", \"瑕疵\", \"不如\", \"烟味\", \"暗\", \"有味道\", \"该扔了\", \"一股味道\", \"没吃\", \"不评论\", \"凑活\", \"太贵\", \"尴尬\", \"不是特别好\",\n",
    "                 \"不是很好\", \"不舒服\", \"不在\", \"地面存水\", \"不好\", \"没有\", \"不方便\", \"不相称\", \"弱\", \"不隔音\", \"郁闷\", \"生硬\", \"不明澈\", \"不是很方便\", \n",
    "                 \"没声\", \"年头\", \"远\", \"吵\", \"不畅\", \"陈旧\", \"不好吃\", \"不要吃\", \"太差\", \"费劲\", \"太小\", \"破\", \"不给力\", \"感冒\",\"太少\", \"很贵\", \n",
    "                 \"太大\", \"摸黑\", \"只有\", \"不开\", \"不亮\", \"无人\", \"没法\", \"陈旧\", \"缺点\", \"用过\", \"坏的\", \"异味严重\", \"异味重\", \"没洗\", \"特别差\", \"很差\", \n",
    "                 \"失望\", \"烂\", \"不足\", \"压抑\", \"糟糕\", \"遗憾\", \"屏蔽\", \"没自助\", \"种类很少\", \"挺少\", \"不得不\", \"不近\", \"慢\", \"不太干净\", \"才\", \"污渍\", \n",
    "                 \"花屏\", \"没反应\", \"不是\", \"忽略\", \"醉了\", \"非常差\", \"嘈杂\", \"才能\", \"小贵\", \"老旧\", \"不是太干净\", \"隔音差\", \"鼾\", \"霉\", \"潮湿\", \"不劲\"\n",
    "                 \"小飞虫\", \"不太方便\", \"不洁净\", \"还要\", \"不好\", \"较差\", \"坏\", \"雪花\", \"不清楚\", \"赔偿\", \"血\", \"才出来\", \"没早餐\", \"不能\", \"烟味\", \n",
    "                 \"简陋\", \"汗味\", \"漏水\", \"窄\", \"形同虚设\", \"闷闷\", \"过期\", \"味道大\", \"堪忧\", \"一般\", \"隔音不好\", \"有点差\", \"该换\", \"一塌糊涂\", \"不是太喜欢\",\n",
    "                 \"不符合\", \"不上档次\", \"没敢\", \"不太干净\", \"不太卫生\", \"很贵\", \"不太好找\", \"不是太友好\", \"不咋样\", \"比较小\", \"住不了\", \"投诉\", \"才有\",\n",
    "                 \"不起作用\", \"难道\", \"跟不上\", \"卡顿\", \"人多\", \"有点挤\", \"太旧\", \"不敢碰\", \"难闻\", \"喉咙\", \"呛\", \"很堵\", \"没睡好\", \"马虎\", \"不够好\", \"不够干净\",\n",
    "                 \"一层灰\", \"一层绣\", \"木讷\", \"被解除\", \"旧漆\", \"松动\", \"不提供\", \"很旧了\", \"斑点\", \"种类比较少\", \"不冷不热\", \"这么差\", \"种类较少\", \"味道很大\", \n",
    "                 \"无法\", \"噪声\", \"凑合\", \"除了床\", \"推销\", \"反味\", \"超冷\", \"不够热\", \"没见\", \"差太多\", \"不提供\", \"看看\", \"品种少\", \"差评\", \"恶劣\", \"恶语\",\n",
    "                 \"漫骂\", \"有些旧\"]\n",
    "\n",
    "def detect_sentiment(review):\n",
    "    negative_count = sum(1 for word in negative_words if word in review)\n",
    "    positive_count = sum(1 for word in positive_words if word in review)\n",
    "\n",
    "    if positive_count > negative_count:\n",
    "        return \"1\"\n",
    "    elif negative_count > positive_count:\n",
    "        return \"-1\"\n",
    "    else:\n",
    "        return \"1\"\n",
    "\n",
    "# 应用到评论列\n",
    "combined_df = pd_beijing_reviews_expanded_clean\n",
    "combined_df['att'] = combined_df['reviews'].apply(detect_sentiment)\n",
    "combined_df['att'] = combined_df['att'].astype(int)\n",
    "combined_df_1000 = combined_df.head(1000)\n",
    "combined_df_1000.to_excel('../dataset/xiecheng/sentiment1000_1214.xlsx') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
