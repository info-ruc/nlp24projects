{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cjGX_zhNFzoI"
      },
      "outputs": [],
      "source": [
        "device = \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlfQ7U5_F4em",
        "outputId": "333f67a5-b922-44b5-d534-190a110fa539"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/Project-NLP-2023"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkVVhEZcGGxM",
        "outputId": "e0d5ed1d-9ee2-4476-e45d-140ad766d41c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Project-NLP-2023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install icecream"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLYGs4ciGgGQ",
        "outputId": "a9603aef-2a16-4c2e-f509-7e28e8226843"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: icecream in /usr/local/lib/python3.10/dist-packages (2.1.3)\n",
            "Requirement already satisfied: colorama>=0.3.9 in /usr/local/lib/python3.10/dist-packages (from icecream) (0.4.6)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from icecream) (2.14.0)\n",
            "Requirement already satisfied: executing>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from icecream) (1.2.0)\n",
            "Requirement already satisfied: asttokens>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from icecream) (2.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from asttokens>=2.0.1->icecream) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kvs-AeOlFzoJ"
      },
      "outputs": [],
      "source": [
        "from datasets import  Tokenized_Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KnfY6LQDFzoK"
      },
      "outputs": [],
      "source": [
        "dataset = Tokenized_Dataset(json_file='negacio_uab_revised_version.json', tokenizer_name='bert-base-multilingual-cased')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RTZBU4-FzoK"
      },
      "source": [
        "do train_test split:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7PLCcTnYFzoL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "# Define the indices for train and test subsets\n",
        "train_indices = range(0,len(dataset)-int(len(dataset)*0.3))\n",
        "test_indices = range(len(dataset)-int(len(dataset)*0.3), len(dataset))\n",
        "\n",
        "# Create Subset datasets based on the defined indices\n",
        "train_data = torch.utils.data.Subset(dataset, train_indices)\n",
        "val_data= torch.utils.data.Subset(dataset, test_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "F01LhEb9FzoL"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size = 5\n",
        "train_loader = DataLoader(train_data,batch_size)\n",
        "val_loader = DataLoader(val_data,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5RNMVyIFzoL"
      },
      "source": [
        "Import pre-trained bert multillingual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaJKHOLTFzoM",
        "outputId": "39c7a201-9713-4ceb-ca46-1fc00e1c5045"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertModel\n",
        "bert = BertModel.from_pretrained('bert-base-multilingual-cased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DUcZAqyBFzoM"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNYhrjt_FzoM"
      },
      "source": [
        "Test a sample:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xXpSOVjnFzoM"
      },
      "outputs": [],
      "source": [
        "#sample = next(iter(train_loader))\n",
        "#sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OTzJtm08FzoN"
      },
      "outputs": [],
      "source": [
        "#predictions = bert(sample[\"x\"])\n",
        "#predictions = predictions[\"last_hidden_state\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "shVTH3gzFzoN"
      },
      "outputs": [],
      "source": [
        "#predictions.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "R_pWq-AbFzoN"
      },
      "outputs": [],
      "source": [
        "#tags = sample[\"y\"]\n",
        "#tags.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "k8AvXVQ3FzoN"
      },
      "outputs": [],
      "source": [
        "#tags.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5u1desmFzoN"
      },
      "source": [
        "We'll define a tagger model that has a linear layer that helps project the last hidden state into the vocab we have. We'll further have a dropout for regularisation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WKZE5IYOFzoN"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BERT_Tagger(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 output_dim, \n",
        "                 dropout):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.bert = bert\n",
        "        \n",
        "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
        "        \n",
        "        self.fc = nn.Linear(embedding_dim,output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, tokens):\n",
        "        \n",
        "        bert_out = self.bert(tokens)[\"last_hidden_state\"]\n",
        "        \n",
        "        predictions = self.fc(bert_out)\n",
        "        \n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#bert_tagger = BERT_Tagger(bert,5,0.1)\n",
        "#torch.save(bert_tagger.state_dict(),\"finetuned_bert.pt\")\n",
        "bert_tagger = torch.load(\"finetuned_bert.pt\",map_location=torch.device('cpu'))"
      ],
      "metadata": {
        "id": "ZxpokIT35zUM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPnoITmWQp6o",
        "outputId": "be3fbb9f-3281-455d-956a-73d1a64fecd5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function torch.serialization.save(obj: object, f: Union[str, os.PathLike, BinaryIO, IO[bytes]], pickle_module: Any = <module 'pickle' from '/usr/lib/python3.10/pickle.py'>, pickle_protocol: int = 2, _use_new_zipfile_serialization: bool = True) -> None>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Q6-jraoZFzoO"
      },
      "outputs": [],
      "source": [
        "#out = bert_tagger(sample[\"x\"])\n",
        "#out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "PtDL0mEaFzoO"
      },
      "outputs": [],
      "source": [
        "def categorical_accuracy(preds, y, tag_pad_idx):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
        "    non_pad_elements = (y != tag_pad_idx).nonzero()\n",
        "    correct = max_preds[non_pad_elements].squeeze(1).eq(y[non_pad_elements])\n",
        "    return correct.sum() / torch.FloatTensor([y[non_pad_elements].shape[0]]).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "LB_tRRVkFzoO"
      },
      "outputs": [],
      "source": [
        "min_loss = 100000\n",
        "def train(model, epochs, dataloader, optimizer_full, criterion_specific, criterion, tag_pad_idx):    \n",
        "    model.train()\n",
        "\n",
        "    for i in range(epochs):\n",
        "        for j, batch in enumerate(dataloader):\n",
        "            tokens = batch[\"x\"].to(device)\n",
        "            tags = batch[\"y\"].to(device)\n",
        "            #look if all tags in the batch are none, if so skip\n",
        "            #if torch.equal(tags, torch.tensor([[dataset.uniq_tags.index(\"NONE\")]*tags.shape[1]]).to(device)) :\n",
        "            #    continue #skip batch\n",
        "                     \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            #text = [sent len, batch size]\n",
        "            \n",
        "            predictions = model(tokens)\n",
        "            predictions = predictions.view(-1, predictions.shape[-1]) #merge sent len and batch dimensions\n",
        "\n",
        "            tags = tags.view(-1)\n",
        "            #predictions  = [sent len * batch size, output dim]\n",
        "            #tags = [sent len * batch size]\n",
        "            \n",
        "            loss_full = criterion_full(predictions, tags)\n",
        "            loss_specific = criterion_specific(predictions, tags)\n",
        "            loss = loss_full*0.2 + loss_specific*0.8\n",
        "                    \n",
        "            acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
        "            \n",
        "            if loss.item() < min_loss:\n",
        "              torch.save(model,\"finetuned_bert.pt\")\n",
        "\n",
        "            loss.backward()\n",
        "            \n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "            print(f\"epoch:{i} batch:{j} loss:{loss.item()} acc:{acc.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "sbli5uT4FzoO"
      },
      "outputs": [],
      "source": [
        "#make the criterion not count loss on \"NONE\" tag\n",
        "criterion_specific = nn.CrossEntropyLoss(ignore_index = dataset.uniq_tags.index(\"NONE\"))\n",
        "criterion_full = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "pbAf5Jd9FzoO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "377c3846-5316-424f-d45e-93efaa4cc209"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-b6f069f1af90>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5e-5\u001b[0m \u001b[0;31m#as recomended in BERT paper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_tagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'parameters'"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "LEARNING_RATE = 5e-5 #as recomended in BERT paper\n",
        "optimizer = optim.Adam(bert_tagger.parameters(), lr = LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMRbfuK9FzoO"
      },
      "outputs": [],
      "source": [
        "bert_tagger = bert_tagger.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUAxu2qeFzoO"
      },
      "outputs": [],
      "source": [
        "tag_pad_idx = dataset.uniq_tags.index(\"NONE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtcYGJKCFzoO"
      },
      "outputs": [],
      "source": [
        "train(bert_tagger,1,train_loader,optimizer,criterion_full,criterion_specific,10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(bert_tagger,2,train_loader,optimizer,criterion,10)"
      ],
      "metadata": {
        "id": "BLgFo7QlizNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmaVBwHHFzoP"
      },
      "source": [
        "Test the model qualititavely:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8DA0tyMFzoP"
      },
      "outputs": [],
      "source": [
        "from colorama import Fore, Back, Style"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MX7C2aYoFzoP"
      },
      "outputs": [],
      "source": [
        "def eval(model,dataset,n_batches,tag_pad_idx,uniq_tags):\n",
        "    colors = [Fore.BLUE,Fore.RED,Fore.GREEN,Fore.CYAN,Fore.WHITE]\n",
        "    reference_tag_txt = [colors[i]+uniq_tags[i] for i in range(len(uniq_tags))]\n",
        "    reference_tag_txt = \" \".join(reference_tag_txt)\n",
        "    \n",
        "    for i in range(0,n_batches*512,512):\n",
        "        batch = dataset.__getitem__(i)\n",
        "        tokens = batch[\"x\"].to(device).unsqueeze(0)\n",
        "        tags = batch[\"y\"].to(device).unsqueeze(0)\n",
        "        tokens_txt = batch[\"x_ref\"]\n",
        "        predictions = model(tokens)\n",
        "        predictions = predictions.view(-1, predictions.shape[-1]) #merge sent len and batch dimensions\n",
        "        predictions = torch.argmax(predictions,axis=1).to(\"cpu\").numpy()\n",
        "        tags = tags.view(-1)\n",
        "        \n",
        "        txt = \"\"\n",
        "        txt_pred = \"\"\n",
        "        for tok,tag,pred in zip(tokens_txt,tags,predictions):\n",
        "            if tok[0] == \"#\":\n",
        "                txt += colors[tag]+tok.replace(\"#\",\"\")\n",
        "                txt_pred += colors[pred]+tok.replace(\"#\",\"\")\n",
        "\n",
        "            else:\n",
        "                txt += \" \" + colors[tag]+tok.replace(\"#\",\"\")\n",
        "                txt_pred += \" \" + colors[pred]+tok.replace(\"#\",\"\")\n",
        "\n",
        "        print(reference_tag_txt)\n",
        "        print(Fore.WHITE+\"-------------------True-------------------\")\n",
        "        print(txt)\n",
        "        print(Fore.WHITE+\"-------------------True-------------------\")\n",
        "        print(Fore.WHITE+\"-------------------Pred-------------------\")\n",
        "        print(txt_pred)\n",
        "        print(Fore.WHITE+\"-------------------Pred-------------------\")\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vo292atFzoP"
      },
      "outputs": [],
      "source": [
        "eval(bert_tagger,val_data,10,tag_pad_idx,dataset.uniq_tags)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.9 ('ML')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "da600ade1a771c82ddf6d22a5a41f856afbf3528a3611e1c80e3ac6da17c9450"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}