{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baff11b4-c4d4-4dfc-af92-599e99cd85e5",
   "metadata": {},
   "source": [
    "# **<center>外卖订单评价检验</center>**\n",
    "## **<center>文本情感分析</center>**\n",
    "\n",
    "\n",
    "<h4 style=\"text-align:right\">陈珺琨 2021200142</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf6fa57-473c-4a67-85fb-e0f8002e38e6",
   "metadata": {},
   "source": [
    "## 一、导入基本库与数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2758ac-1eb3-4ebe-861d-cf5d636a97bc",
   "metadata": {},
   "source": [
    "### 1.1 导入基本库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d6a8c3a9-860b-41c5-8646-6c52ee4f9f67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 100x100 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 导入需要的数据包\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import patchworklib as pw\n",
    "import threadpoolctl\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime \n",
    "import random\n",
    "import seaborn as sns\n",
    "import os\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f20bbc7-e36d-4e2e-a4bb-1bd18704acb1",
   "metadata": {},
   "source": [
    "### 1.2 加载Bert模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b01b3892-d54d-4f5f-9d15-9530859fa774",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\chennxx\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# 加载预训练的BERT tokenizer\n",
    "model = AutoModelForSequenceClassification.from_pretrained('google-bert/bert-base-chinese', num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cd5e1c-438f-4dfe-94ad-a10cfee1f96f",
   "metadata": {},
   "source": [
    "### 1.3 载入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee81a2d1-0d8d-424b-9f9a-6be5eb296e34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# 加载美团外卖数据集\n",
    "dataset = load_dataset('XiangPan/waimai_10k')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff677c2-3ac9-435a-bb2f-3f38bf58d277",
   "metadata": {},
   "source": [
    "## 二、Stage1-订单评价情感分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7797101d-4a7d-4d3d-a877-30bfc0578eff",
   "metadata": {},
   "source": [
    "### 2.1 训练Bert模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa123780-f18c-4ddf-896b-c2e68516dccd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\"accuracy\": accuracy_score(labels, predictions)}\n",
    "\n",
    "def predict(text, model, tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_class = torch.argmax(logits).item()\n",
    "\n",
    "    return int(predicted_class)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-chinese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80a96d3c-b33f-405e-9fd3-692d795d5948",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1125' max='1125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1125/1125 8:48:19, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.318600</td>\n",
       "      <td>0.371693</td>\n",
       "      <td>0.890945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 训练Bert模型\n",
    "\n",
    "CLASS_NAME = {0: \"negative\", 1: \"positive\"}\n",
    "\n",
    "dataset = load_dataset(\"XiangPan/waimai_10k\")\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# 将数据集划分为训练集和验证集\n",
    "datasets_all = tokenized_datasets[\"train\"].shuffle(seed=42)\n",
    "train_dataset = datasets_all.select(range(9000))\n",
    "eval_dataset = datasets_all.select(range(9001,11987))\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-chinese\", num_labels=2)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=1,\n",
    "    logging_steps=50,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# 测试模型\n",
    "test_reviews = [\n",
    "    \"菜品非常丰富。\"\n",
    "]\n",
    "\n",
    "model.to('cpu')\n",
    "text_list = []\n",
    "for review in test_reviews:\n",
    "    label = predict(review, model, tokenizer)\n",
    "    text_list.append(review + \" - \" + CLASS_NAME[label])\n",
    "\n",
    "# 使用 Matplotlib 展示结果\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = [CLASS_NAME[label] for _ in test_reviews]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(len(test_reviews)), [1]*len(test_reviews), tick_label=text_list)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Model Predictions\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32545be4-d31b-4361-8183-05f652add52b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>菜品非常丰富，每道菜都非常美味可口。特别是他们家的宫保鸡丁，味道真的很棒，鸡肉鲜嫩多汁，酱汁...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>这家外卖不仅菜品味道好，包装也非常精美。每次收到外卖都感觉像是收到了礼物一样，包装盒干净整洁...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>我对这家外卖印象非常深刻，因为他们家的菜品不仅美味，而且非常健康。每道菜都使用新鲜的食材，吃...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>非常正宗，让我有一种回到家乡的感觉。特别是他们家的麻婆豆腐，味道特别地道，辣得很过瘾。价格也...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>配送速度真的是超乎想象，每次点餐从下单到送达都不会超过30分钟。菜品的味道也一如既往的好，特...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>配送速度实在是太慢了，我下单之后足足等了一个小时才送到。收到的时候，菜已经凉了，味道也大打折...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>菜品味道一般，而且份量也不足。点了一份宫保鸡丁，结果鸡肉少得可怜，基本都是青椒和花生，吃起来...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>简陋，收到的时候盒子已经变形，汤汁也洒了出来。配送员的态度也很冷淡，完全没有服务意识。菜品的...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>每一道菜都非常油腻，吃起来很不舒服。特别是他们家的红烧肉，油腻得让人无法下咽，完全没有食欲。...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>这家外卖的价格实在是太高了，性价比很低。点了一份麻婆豆腐，味道很一般，完全不值这个价钱。而且...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>女朋友和别人在酒店，让我给她点外卖。里面居然有生黄瓜，为什么会有生的黄瓜，我女朋友最讨厌吃了...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>直接差评吸管为什么不是90个，小心我老大坠机，直接向你无限肘击</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>备注都不看的吗，说了要另带小米辣和辣椒面醋</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>这个土豆粉我知道，上次我们村闹洪灾就是这个土豆粉把水吸完的</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Review     Class\n",
       "0   菜品非常丰富，每道菜都非常美味可口。特别是他们家的宫保鸡丁，味道真的很棒，鸡肉鲜嫩多汁，酱汁...  positive\n",
       "1   这家外卖不仅菜品味道好，包装也非常精美。每次收到外卖都感觉像是收到了礼物一样，包装盒干净整洁...  positive\n",
       "2   我对这家外卖印象非常深刻，因为他们家的菜品不仅美味，而且非常健康。每道菜都使用新鲜的食材，吃...  positive\n",
       "3   非常正宗，让我有一种回到家乡的感觉。特别是他们家的麻婆豆腐，味道特别地道，辣得很过瘾。价格也...  positive\n",
       "4   配送速度真的是超乎想象，每次点餐从下单到送达都不会超过30分钟。菜品的味道也一如既往的好，特...  positive\n",
       "5   配送速度实在是太慢了，我下单之后足足等了一个小时才送到。收到的时候，菜已经凉了，味道也大打折...  negative\n",
       "6   菜品味道一般，而且份量也不足。点了一份宫保鸡丁，结果鸡肉少得可怜，基本都是青椒和花生，吃起来...  negative\n",
       "7   简陋，收到的时候盒子已经变形，汤汁也洒了出来。配送员的态度也很冷淡，完全没有服务意识。菜品的...  negative\n",
       "8   每一道菜都非常油腻，吃起来很不舒服。特别是他们家的红烧肉，油腻得让人无法下咽，完全没有食欲。...  negative\n",
       "9   这家外卖的价格实在是太高了，性价比很低。点了一份麻婆豆腐，味道很一般，完全不值这个价钱。而且...  negative\n",
       "10  女朋友和别人在酒店，让我给她点外卖。里面居然有生黄瓜，为什么会有生的黄瓜，我女朋友最讨厌吃了...  negative\n",
       "11                    直接差评吸管为什么不是90个，小心我老大坠机，直接向你无限肘击  negative\n",
       "12                              备注都不看的吗，说了要另带小米辣和辣椒面醋  negative\n",
       "13                      这个土豆粉我知道，上次我们村闹洪灾就是这个土豆粉把水吸完的  positive"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试模型\n",
    "test_reviews = [\n",
    "    \"菜品非常丰富，每道菜都非常美味可口。特别是他们家的宫保鸡丁，味道真的很棒，鸡肉鲜嫩多汁，酱汁调味适中。每次点餐都能有新的惊喜，感觉每一道菜都经过精心烹饪。送餐速度也很快，菜到的时候还是热乎乎的，真的很满意。\",\n",
    "    \"这家外卖不仅菜品味道好，包装也非常精美。每次收到外卖都感觉像是收到了礼物一样，包装盒干净整洁，里面还附赠了餐巾纸和湿巾，特别贴心。配送员的态度也很好，总是面带微笑，送餐速度也很快。总之，是一次非常愉快的用餐体验。\",\n",
    "    \"我对这家外卖印象非常深刻，因为他们家的菜品不仅美味，而且非常健康。每道菜都使用新鲜的食材，吃起来非常放心。特别喜欢他们家的沙拉，蔬菜非常新鲜，调料也很特别。每次点餐都能感受到店家的用心，是我目前最喜欢的一家外卖店。\",\n",
    "    \"非常正宗，让我有一种回到家乡的感觉。特别是他们家的麻婆豆腐，味道特别地道，辣得很过瘾。价格也非常实惠，分量足够，一份就能吃饱。每次点餐都觉得物超所值，非常推荐！\",\n",
    "    \"配送速度真的是超乎想象，每次点餐从下单到送达都不会超过30分钟。菜品的味道也一如既往的好，特别喜欢他们家的红烧牛肉，肉质酥烂入味，搭配的土豆也煮得刚刚好。每次点餐都很期待，绝对值得一试。\",\n",
    "    \n",
    "    \"配送速度实在是太慢了，我下单之后足足等了一个小时才送到。收到的时候，菜已经凉了，味道也大打折扣。特别是炸鸡块，完全没有了刚炸出来的香脆口感，感觉很失望。希望能改进配送速度，否则不太敢再点。\",\n",
    "    \"菜品味道一般，而且份量也不足。点了一份宫保鸡丁，结果鸡肉少得可怜，基本都是青椒和花生，吃起来非常失望。价格也不算便宜，总感觉物不所值。希望店家能改进菜品的份量和质量。\",\n",
    "    \"简陋，收到的时候盒子已经变形，汤汁也洒了出来。配送员的态度也很冷淡，完全没有服务意识。菜品的味道也不怎么样，感觉就像是随便炒出来的，没有一点特色。这样的用餐体验真的很糟糕。\",\n",
    "    \"每一道菜都非常油腻，吃起来很不舒服。特别是他们家的红烧肉，油腻得让人无法下咽，完全没有食欲。配送速度也很慢，收到的时候菜已经冷了。希望店家能改进菜品质量，否则真的不会再点了。\",\n",
    "    \"这家外卖的价格实在是太高了，性价比很低。点了一份麻婆豆腐，味道很一般，完全不值这个价钱。而且份量也很少，根本吃不饱。配送速度也不快，整体用餐体验非常差。希望店家能调整价格，提升菜品质量。\",\n",
    "    \"女朋友和别人在酒店，让我给她点外卖。里面居然有生黄瓜，为什么会有生的黄瓜，我女朋友最讨厌吃了。现在要闹着和我分手，怎么办。我受不了了。为什么要放黄瓜，如果放黄瓜话，她就不会和我分手了……\",\n",
    "    \"直接差评吸管为什么不是90个，小心我老大坠机，直接向你无限肘击\",\n",
    "    \"备注都不看的吗，说了要另带小米辣和辣椒面醋\",\n",
    "    \"这个土豆粉我知道，上次我们村闹洪灾就是这个土豆粉把水吸完的\"\n",
    "]\n",
    "\n",
    "\n",
    "model.to('cpu')\n",
    "text_list = []\n",
    "for review in test_reviews:\n",
    "    label = predict(review, model, tokenizer)\n",
    "    text_list.append([review, CLASS_NAME[label]])  # 将review和类别名称作为一个列表添加\n",
    "\n",
    "# 创建DataFrame，指定列名\n",
    "result = pd.DataFrame(text_list, columns=['Review', 'Class'])\n",
    "\n",
    "# 显示DataFrame\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68198f3c-37a7-4bb1-bc64-8037a86e48bb",
   "metadata": {},
   "source": [
    "### 2.2 保存原数据集BERT向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3604dc17-927e-4153-9685-2d59f2d07f1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process  500  texts.\n",
      "Process  1000  texts.\n",
      "Process  1500  texts.\n",
      "Process  2000  texts.\n",
      "Process  2500  texts.\n",
      "Process  3000  texts.\n",
      "Process  3500  texts.\n",
      "Process  4000  texts.\n",
      "Process  4500  texts.\n",
      "Process  5000  texts.\n",
      "Process  5500  texts.\n",
      "Process  6000  texts.\n",
      "Process  6500  texts.\n",
      "Process  7000  texts.\n",
      "Process  7500  texts.\n",
      "Process  8000  texts.\n",
      "Process  8500  texts.\n",
      "Process  9000  texts.\n",
      "Process  9500  texts.\n",
      "Process  10000  texts.\n",
      "Process  10500  texts.\n",
      "Process  11000  texts.\n",
      "Process  11500  texts.\n",
      "   problemEB_0  problemEB_1  problemEB_2  problemEB_3  problemEB_4  \\\n",
      "0     0.002786     0.350907    -0.590879     0.624839     0.275236   \n",
      "1    -0.388467     0.344315     0.032715    -0.823201     0.978599   \n",
      "2     0.239318     0.292602     0.541065    -0.180603     0.326330   \n",
      "3     0.463375     0.265843    -0.954373    -0.184800     0.771330   \n",
      "4     0.536140     0.671927     0.256286     0.845530     0.309015   \n",
      "\n",
      "   problemEB_5  problemEB_6  problemEB_7  problemEB_8  problemEB_9  ...  \\\n",
      "0    -0.998189     0.249843    -1.160770    -0.333895     0.661828  ...   \n",
      "1    -1.090205     0.495675    -0.690717    -0.325970     0.588440  ...   \n",
      "2    -1.056555     0.003999    -1.555352     0.225033     0.333953  ...   \n",
      "3    -1.255783     0.268276    -1.316844    -0.101130     0.470056  ...   \n",
      "4    -1.011913     0.090691    -0.755432    -0.736551     0.488083  ...   \n",
      "\n",
      "   problemEB_758  problemEB_759  problemEB_760  problemEB_761  problemEB_762  \\\n",
      "0      -0.536378       0.239979       0.343862       0.967223       0.913974   \n",
      "1      -0.829643      -0.294156      -0.028544      -1.372434      -0.540188   \n",
      "2      -0.635317       0.872438       0.532460       0.822976       0.994111   \n",
      "3      -0.718720      -0.206989       0.382353       0.192804       1.041080   \n",
      "4      -0.638142       0.317016       0.473254       0.544670       1.111727   \n",
      "\n",
      "   problemEB_763  problemEB_764  problemEB_765  problemEB_766  problemEB_767  \n",
      "0      -0.801003      -0.047445      -0.197605       0.059263      -0.138500  \n",
      "1      -0.806019       0.476399       0.238898      -0.232822      -0.024937  \n",
      "2      -1.065691       0.190030      -1.125029       0.076238       0.196769  \n",
      "3      -0.851206      -0.136673      -0.067548       0.217650      -0.122807  \n",
      "4      -0.678114      -0.265979      -1.327919       0.226817      -0.379921  \n",
      "\n",
      "[5 rows x 768 columns]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv(\"waimai.csv\")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-base-chinese\")\n",
    "\n",
    "model = BertModel.from_pretrained(\"google-bert/bert-base-chinese\", num_labels=2)\n",
    "\n",
    "# 将模型设置为评估模式\n",
    "model.eval()\n",
    "\n",
    "# 获取 BERT 的文本嵌入\n",
    "def get_bert_embeddings(texts):\n",
    "    embeddings = []\n",
    "    cnt = 0\n",
    "    for text in texts:\n",
    "        cnt += 1\n",
    "        if cnt % 500 == 0:\n",
    "            print(\"Process \", cnt, \" texts.\")\n",
    "\n",
    "        inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        cls_embedding = outputs.last_hidden_state[0, 0, :].numpy()\n",
    "        embeddings.append(cls_embedding)\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "embeddings = get_bert_embeddings(df.iloc[:,1].tolist())\n",
    "embeddings_df = pd.DataFrame(embeddings)\n",
    "\n",
    "embeddings_df.columns = [f'problemEB_{i}' for i in range(embeddings_df.shape[1])]\n",
    "\n",
    "# 查看 DataFrame\n",
    "print(embeddings_df.head())\n",
    "\n",
    "embeddings_df.to_csv(\"bert_emb.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0432ee-39b6-49a8-add2-6f001d061a4e",
   "metadata": {},
   "source": [
    "## 三、Stage2-订单评价讽刺分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e11fcd4-c82d-4e58-89c6-0f721cf0dc07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                               text\n",
      "0     0  这是最受气包的一届总统特朗普：我被陷害，我被诬告，我冤枉！特朗普反对者：我们只是在行使民主自...\n",
      "1     0                        那些相信经济全球化会走向命运共同体的人现在天天被打脸。\n",
      "2     0                                     嗯，这很西方，有强盗思维逻辑\n",
      "3     0  试错的成本应该资本家承担，而不是消费者，别偷换概念。你试了，发现错了，就要及时召回，该换的换...\n",
      "4     0                    呵呵呵呵，站着说话不腰疼，棚户区改造你们怎么不说，穷人不是人？\n",
      "  label                     text\n",
      "0     0             三文鱼：“你说谁呢？！”\n",
      "1     0  来，看我打开直播，给出致命一击！呀呀呀，跳劈！\n",
      "2     0             英国皇室应该可以出面了。\n",
      "3     0            谷歌搜索不是抄袭雅虎的吗？\n",
      "4     0        要是忍了又没发展出来那不骂得更惨？\n",
      "          text_len\n",
      "count  2119.000000\n",
      "mean     23.719679\n",
      "std      17.966992\n",
      "min       1.000000\n",
      "25%      11.500000\n",
      "50%      19.000000\n",
      "75%      30.000000\n",
      "max     116.000000\n"
     ]
    }
   ],
   "source": [
    "# 读取txt文件\n",
    "def read_txt_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = [_.strip() for _ in f.readlines()]\n",
    "\n",
    "    labels, texts = [], []\n",
    "    for line in content:\n",
    "        parts = line.split()\n",
    "        #print(parts)\n",
    "        label, text = parts[0], ''.join(parts[1:])\n",
    "        labels.append(label)\n",
    "        texts.append(text)\n",
    "\n",
    "    return labels, texts\n",
    "\n",
    "\n",
    "file_path = 'Chinese-S/data/train.txt'\n",
    "labels, texts = read_txt_file(file_path)\n",
    "s_train_df = pd.DataFrame({'label': labels, 'text': texts})\n",
    "\n",
    "file_path = 'Chinese-S/data/test.txt'\n",
    "labels, texts = read_txt_file(file_path)\n",
    "s_test_df = pd.DataFrame({'label': labels, 'text': texts})\n",
    "\n",
    "print(s_train_df.head())\n",
    "print(s_test_df.head())\n",
    "\n",
    "s_train_df['text_len'] = s_train_df['text'].apply(lambda x: len(x))\n",
    "print(s_train_df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7e2991-e9b2-496c-843a-a644cac1ac9a",
   "metadata": {},
   "source": [
    "### 3.1 多特征讽刺识别"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2f7920-012b-49c9-b8fd-87b24dd7a806",
   "metadata": {},
   "source": [
    "根据两篇基于单语句讽刺检测的论文，它们给出了一系列针对讽刺识别的特征，例如**情感极性**，**基于句法、基于模式的特征向量**。本点针对这两种方案进行操作。\n",
    "\n",
    "1. **情感极性**：Recognition of Sarcasm in Tweets Based on Concept Level Sentiment Analysis and Supervised Learning Approaches(Piyoros Tungthamthiti, 2014)；\n",
    "\n",
    "2. **基于句法、基于模式的特征向量**：Enhanced Sentiment Learning Using Twitter Hashtags and Smileys(Dmitry Davidov, Oren Tsur, 2010)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d36316d-a9ec-4726-818d-1b81031fa468",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3.1.1 情感极性分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8be94d-7fe7-4bea-a2d5-aff6593093bc",
   "metadata": {},
   "source": [
    "原文基于英文语料，采用SentiStrength和SenticNet词典进行词汇的情感分析；在中文语料情境下，尝试使用SnowNLP模型、或更换为cnsenti情感词典进行分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e31d22d7-121b-4a30-9660-6f0940f3d4de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>这是最受气包的一届总统特朗普：我被陷害，我被诬告，我冤枉！特朗普反对者：我们只是在行使民主自...</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>那些相信经济全球化会走向命运共同体的人现在天天被打脸。</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>嗯，这很西方，有强盗思维逻辑</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>试错的成本应该资本家承担，而不是消费者，别偷换概念。你试了，发现错了，就要及时召回，该换的换...</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>呵呵呵呵，站着说话不腰疼，棚户区改造你们怎么不说，穷人不是人？</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>0</td>\n",
       "      <td>就是英国人自己拍的电视机，可以搜下，拍的很不错，相当有讽刺风格</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>0</td>\n",
       "      <td>宣战！</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>0</td>\n",
       "      <td>卡钦斯基是图</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>0</td>\n",
       "      <td>国会姥爷：又想从我这骗钱，地主家也没有余粮了啊</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118</th>\n",
       "      <td>0</td>\n",
       "      <td>太少了，十天才一次，表示不过瘾</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2119 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  text_len\n",
       "0        0  这是最受气包的一届总统特朗普：我被陷害，我被诬告，我冤枉！特朗普反对者：我们只是在行使民主自...        52\n",
       "1        0                        那些相信经济全球化会走向命运共同体的人现在天天被打脸。        27\n",
       "2        0                                     嗯，这很西方，有强盗思维逻辑        14\n",
       "3        0  试错的成本应该资本家承担，而不是消费者，别偷换概念。你试了，发现错了，就要及时召回，该换的换...        93\n",
       "4        0                    呵呵呵呵，站着说话不腰疼，棚户区改造你们怎么不说，穷人不是人？        31\n",
       "...    ...                                                ...       ...\n",
       "2114     0                    就是英国人自己拍的电视机，可以搜下，拍的很不错，相当有讽刺风格        31\n",
       "2115     0                                                宣战！         3\n",
       "2116     0                                             卡钦斯基是图         6\n",
       "2117     0                            国会姥爷：又想从我这骗钱，地主家也没有余粮了啊        23\n",
       "2118     0                                    太少了，十天才一次，表示不过瘾        15\n",
       "\n",
       "[2119 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 讽刺语句数据集\n",
    "s_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe4064f-9ab5-4ca9-910d-2400b0cff37e",
   "metadata": {},
   "source": [
    "##### 3.1.1.1 SnowNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4ba0122-aedd-4edd-bc0e-c7c332de4178",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 数据预处理和特征工程\n",
    "def calculate_word_sentiment_scores(text):\n",
    "    s = SnowNLP(text)  # 创建SnowNLP对象\n",
    "    words = s.words  # 使用SnowNLP的分词功能\n",
    "    sum_pos_score = 0\n",
    "    sum_neg_score = 0\n",
    "    for word in words:\n",
    "        word_sn = SnowNLP(word)\n",
    "        # 计算正面和负面分数\n",
    "        if word_sn.sentiments > 0.5:\n",
    "            sum_pos_score += 1\n",
    "        elif word_sn.sentiments < 0.5:  # 注意这里的条件应该是小于0.5，因为sentiments属性不会返回负值\n",
    "            sum_neg_score += 1\n",
    "    return sum_pos_score, sum_neg_score\n",
    "\n",
    "# 应用到数据集\n",
    "s_train_df['sum_pos_score'], s_train_df['sum_neg_score'] = zip(*s_train_df['text'].apply(calculate_word_sentiment_scores))\n",
    "\n",
    "# 特征选择\n",
    "X = s_train_df[['text_len', 'sum_pos_score', 'sum_neg_score']]\n",
    "y = s_train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "574cfc6f-7ba7-4aab-ab1d-79ce603a7bab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       这是最受气包的一届总统特朗普：我被陷害，我被诬告，我冤枉！特朗普反对者：我们只是在行使民主自...\n",
       "1                             那些相信经济全球化会走向命运共同体的人现在天天被打脸。\n",
       "2                                          嗯，这很西方，有强盗思维逻辑\n",
       "3       试错的成本应该资本家承担，而不是消费者，别偷换概念。你试了，发现错了，就要及时召回，该换的换...\n",
       "4                         呵呵呵呵，站着说话不腰疼，棚户区改造你们怎么不说，穷人不是人？\n",
       "                              ...                        \n",
       "2114                      就是英国人自己拍的电视机，可以搜下，拍的很不错，相当有讽刺风格\n",
       "2115                                                  宣战！\n",
       "2116                                               卡钦斯基是图\n",
       "2117                              国会姥爷：又想从我这骗钱，地主家也没有余粮了啊\n",
       "2118                                      太少了，十天才一次，表示不过瘾\n",
       "Name: text, Length: 2119, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_train_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0fafc2a-bd3b-473e-86b2-96aa0c605cd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['真山', '真', '水', '拍', '成假', '山假', '水', '，', '这', '导演', '太', '厉害', '了', '。']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = SnowNLP(\"真山真水拍成假山假水，这导演太厉害了。\").words\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e894f27-8f31-4b0d-b7a8-f673d6e412ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "真山 0.5744488213563617\n",
      "真 0.5305096913137115\n",
      "水 0.33777777777777795\n",
      "拍 0.4782608695652175\n",
      "水 0.33777777777777795\n",
      "， 0.5262327818078083\n",
      "这 0.5262327818078083\n",
      "导演 0.7199999999999998\n",
      "太 0.34387502381406\n",
      "厉害 0.35964912280701733\n",
      "了 0.5262327818078083\n",
      "。 0.5262327818078083\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    word_sn = SnowNLP(word)\n",
    "    # 计算正面和负面分数\n",
    "    if word_sn.sentiments > 0.5:\n",
    "        print(word,word_sn.sentiments)\n",
    "    elif word_sn.sentiments < 0.5:  # 注意这里的条件应该是小于0.5，因为sentiments属性不会返回负值\n",
    "        print(word,word_sn.sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5624c178-50b6-46a1-b5e5-3b611466c462",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "太 0.34387502381406\n",
      "厉害 0.35964912280701733\n"
     ]
    }
   ],
   "source": [
    "# 遍历分词结果和词性标注\n",
    "for word, flag in SnowNLP(\"真山真水拍成假山假水，这导演太厉害了。\").tags:\n",
    "    if flag == 'a' or flag == 'd':  # 筛选形容词和副词\n",
    "        word_sn = SnowNLP(word)\n",
    "        # 计算正面和负面分数\n",
    "        if word_sn.sentiments > 0.5:\n",
    "            print(word,word_sn.sentiments)\n",
    "        elif word_sn.sentiments < 0.5:\n",
    "            print(word,word_sn.sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeec39f-6eb0-41ed-b9b8-bbc3ad22fd07",
   "metadata": {},
   "source": [
    "SnowNLP主要对语段、句子做情感分析，对独立词汇的分析效果较差。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2800fec-4a02-49d0-9c7a-9e027ea2e465",
   "metadata": {},
   "source": [
    "##### 3.1.1.2 中文情感分析库CnSenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "91448721-1a3d-4d71-8adc-5a72d2d5af2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'words': 36, 'sentences': 1, 'pos': 3, 'neg': 2}\n"
     ]
    }
   ],
   "source": [
    "from cnsenti import Sentiment\n",
    "\n",
    "senti = Sentiment()\n",
    "test_text= '今天真是我的幸运日，不仅车子被堵在路上动弹不得，还意外地享受了一顿昂贵的罚单早餐，我简直‘爱’极了这样的惊喜！'\n",
    "result = senti.sentiment_count(test_text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ebc353-1f90-4667-880d-d98d26e2d584",
   "metadata": {},
   "source": [
    "上述语句具有3个正面情绪词汇、2个负面情绪词汇，很有可能是讽刺语句。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "629fdb5e-45ee-4c0b-b14b-4f5eb85d71ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 数据预处理和特征工程\n",
    "def calculate_sentiment_scores(text):\n",
    "    result = senti.sentiment_count(text)  # 使用cnsenti进行情感分析\n",
    "    sum_pos_score = result['pos']\n",
    "    sum_neg_score = result['neg']\n",
    "    return sum_pos_score, sum_neg_score\n",
    "\n",
    "# 应用到数据集\n",
    "s_train_df['sum_pos_score'], s_train_df['sum_neg_score'] = zip(*s_train_df['text'].apply(calculate_sentiment_scores))\n",
    "# 判断极性\n",
    "s_train_df['polarity'] = s_train_df.apply(lambda row: 1 if row['sum_pos_score'] != 0 and row['sum_neg_score'] != 0 else 0, axis=1).astype(int)\n",
    "\n",
    "# 特征选择\n",
    "X = s_train_df[['text', 'sum_pos_score', 'sum_neg_score', 'polarity']]\n",
    "y = s_train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "03e02b73-8a28-490e-aaef-699b299910ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.7418593676262388\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.84      1765\n",
      "           1       0.25      0.27      0.26       354\n",
      "\n",
      "    accuracy                           0.74      2119\n",
      "   macro avg       0.55      0.55      0.55      2119\n",
      "weighted avg       0.75      0.74      0.75      2119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 测量拟合效果\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Accuracy score: {}\".format(accuracy_score(s_train_df['polarity'], s_train_df['label'].astype(int))))\n",
    "print(classification_report(s_train_df['polarity'], s_train_df['label'].astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4eda7d-b384-43e9-aff6-1121dfb1ee23",
   "metadata": {},
   "source": [
    "#### 3.1.2 语句特征向量（基于句法）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77dd370-c161-415a-9fea-03eb3c17a909",
   "metadata": {
    "tags": []
   },
   "source": [
    "原论文“基于模式”的方法针对英语效果较好，而中文效果较差；此处仅基于句法制造特征向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e089e942-6e20-42fd-b4b9-b39b908039ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s_train_df.drop(['sentence_length','num_question','num_quotes','num_exclamation'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4e48aa56-7c8f-4b7b-baca-e247934cc66f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_len</th>\n",
       "      <th>sum_pos_score</th>\n",
       "      <th>sum_neg_score</th>\n",
       "      <th>polarity</th>\n",
       "      <th>num_exclamation</th>\n",
       "      <th>num_question</th>\n",
       "      <th>num_quotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>这是最受气包的一届总统特朗普：我被陷害，我被诬告，我冤枉！特朗普反对者：我们只是在行使民主自...</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>那些相信经济全球化会走向命运共同体的人现在天天被打脸。</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>嗯，这很西方，有强盗思维逻辑</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>试错的成本应该资本家承担，而不是消费者，别偷换概念。你试了，发现错了，就要及时召回，该换的换...</td>\n",
       "      <td>93</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>呵呵呵呵，站着说话不腰疼，棚户区改造你们怎么不说，穷人不是人？</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>0</td>\n",
       "      <td>就是英国人自己拍的电视机，可以搜下，拍的很不错，相当有讽刺风格</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>0</td>\n",
       "      <td>宣战！</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>0</td>\n",
       "      <td>卡钦斯基是图</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>0</td>\n",
       "      <td>国会姥爷：又想从我这骗钱，地主家也没有余粮了啊</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118</th>\n",
       "      <td>0</td>\n",
       "      <td>太少了，十天才一次，表示不过瘾</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2119 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  text_len  \\\n",
       "0        0  这是最受气包的一届总统特朗普：我被陷害，我被诬告，我冤枉！特朗普反对者：我们只是在行使民主自...        52   \n",
       "1        0                        那些相信经济全球化会走向命运共同体的人现在天天被打脸。        27   \n",
       "2        0                                     嗯，这很西方，有强盗思维逻辑        14   \n",
       "3        0  试错的成本应该资本家承担，而不是消费者，别偷换概念。你试了，发现错了，就要及时召回，该换的换...        93   \n",
       "4        0                    呵呵呵呵，站着说话不腰疼，棚户区改造你们怎么不说，穷人不是人？        31   \n",
       "...    ...                                                ...       ...   \n",
       "2114     0                    就是英国人自己拍的电视机，可以搜下，拍的很不错，相当有讽刺风格        31   \n",
       "2115     0                                                宣战！         3   \n",
       "2116     0                                             卡钦斯基是图         6   \n",
       "2117     0                            国会姥爷：又想从我这骗钱，地主家也没有余粮了啊        23   \n",
       "2118     0                                    太少了，十天才一次，表示不过瘾        15   \n",
       "\n",
       "      sum_pos_score  sum_neg_score  polarity  num_exclamation  num_question  \\\n",
       "0                 0              2         0                3             0   \n",
       "1                 1              0         0                0             0   \n",
       "2                 1              1         1                0             0   \n",
       "3                 2              2         1                0             0   \n",
       "4                 0              2         0                0             1   \n",
       "...             ...            ...       ...              ...           ...   \n",
       "2114              0              1         0                0             0   \n",
       "2115              0              0         0                1             0   \n",
       "2116              0              0         0                0             0   \n",
       "2117              0              1         0                0             0   \n",
       "2118              1              0         0                0             0   \n",
       "\n",
       "      num_quotes  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "...          ...  \n",
       "2114           0  \n",
       "2115           0  \n",
       "2116           0  \n",
       "2117           0  \n",
       "2118           0  \n",
       "\n",
       "[2119 rows x 9 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# 基于句法的特征向量\n",
    "def punctuation_features(text):\n",
    "    features = {\n",
    "        'num_exclamation': len(re.findall(r'！', text)),\n",
    "        'num_question': len(re.findall(r'？', text)),\n",
    "        'num_quotes': len(re.findall(r'“', text))\n",
    "    }\n",
    "    return features\n",
    "\n",
    "# 应用特征提取函数\n",
    "s_train_df['punctuation_features'] = s_train_df['text'].apply(punctuation_features)\n",
    "\n",
    "# 展开特征\n",
    "s_train_df = s_train_df.join(s_train_df['punctuation_features'].apply(pd.Series))\n",
    "\n",
    "# 删除原始的特征列\n",
    "s_train_df.drop(['punctuation_features'], axis=1, inplace=True)\n",
    "\n",
    "# 查看结果\n",
    "s_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c610a7-7dd6-4850-a334-627dffcd2c12",
   "metadata": {},
   "source": [
    "##### 训练KNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a2c96b66-0d06-4a2c-ad99-cd4391f57142",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.7924528301886793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.98      0.88       338\n",
      "           1       0.40      0.05      0.08        86\n",
      "\n",
      "    accuracy                           0.79       424\n",
      "   macro avg       0.60      0.51      0.48       424\n",
      "weighted avg       0.72      0.79      0.72       424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 应用特征提取函数\n",
    "s_train_df['features'] = s_train_df['text'].apply(punctuation_features)\n",
    "\n",
    "# 将特征转换为DataFrame\n",
    "features_df = s_train_df['features'].apply(pd.Series)\n",
    "\n",
    "# 特征选择\n",
    "X = features_df\n",
    "y = s_train_df['label']\n",
    "\n",
    "# 数据预处理\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 划分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 模型训练\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# 模型评估\n",
    "predictions = knn.predict(X_test)\n",
    "print(\"Accuracy score: {}\".format(accuracy_score(y_test, predictions)))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9ab7ff-80ad-4850-9fa0-6cf107890ee7",
   "metadata": {},
   "source": [
    "##### 训练random forests模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3f5fe0-3859-4ba2-905b-00fcc958600d",
   "metadata": {},
   "source": [
    "多训练一种模型，用于判断是数据集-方法不适配，还是模型选取有问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "013653b0-310f-459e-a33f-8f81e13b3bb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=420, random_state=111)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(n_estimators=420, random_state=111)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=420, random_state=111)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 建构随机森林模型\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=420, random_state=111)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0d002296-319d-46c6-ab77-6fc2f1147b61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.7877358490566038\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.99      0.88       338\n",
      "           1       0.00      0.00      0.00        86\n",
      "\n",
      "    accuracy                           0.79       424\n",
      "   macro avg       0.40      0.49      0.44       424\n",
      "weighted avg       0.63      0.79      0.70       424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 模型评估\n",
    "predictions = rf.predict(X_test)\n",
    "print(\"Accuracy score: {}\".format(accuracy_score(y_test, predictions)))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394f6a3e-80f1-48f1-adbc-e9630b1d9809",
   "metadata": {
    "tags": []
   },
   "source": [
    "利用语句特征向量对该数据集不适用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87841571-d02d-424c-9554-ea339b424264",
   "metadata": {},
   "source": [
    "### 3.2 利用讽刺分析数据集训练深度学习网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9474eef-3bd2-45fd-8a22-610c2e673a18",
   "metadata": {},
   "source": [
    "#### 3.2.1 利用Bert向量初步训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c90f11-4d80-4077-b8d8-1fc57d8d4850",
   "metadata": {},
   "source": [
    "##### 文本转换为embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78b6b09d-3d93-495b-a25f-707c184eed2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin encoding\n",
      "end encoding\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 使用GPU训练\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4,5,6,7,8\"\n",
    "\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, BatchNormalization, Dense\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# 初始化tokenizer和model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-chinese\")\n",
    "model = AutoModel.from_pretrained(\"google-bert/bert-base-chinese\")\n",
    "\n",
    "# 读取文件并进行转换\n",
    "def encode_text(texts):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # 使用最后一层的hidden states的平均值作为句子的表示\n",
    "    embeddings = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "    return embeddings\n",
    "\n",
    "print('begin encoding')\n",
    "train_embeddings = encode_text(s_train_df['text'].tolist())\n",
    "test_embeddings = encode_text(s_test_df['text'].tolist())\n",
    "print('end encoding')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7924009-d991-4851-8542-31bf7e7974dc",
   "metadata": {},
   "source": [
    "##### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2e3cc78a-7e8f-45d5-9ea8-52afc8a8f735",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (2119, 768)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_17\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_17\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,608</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_17               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_17 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │          \u001b[38;5;34m24,608\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_17               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │              \u001b[38;5;34m66\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,802</span> (96.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,802\u001b[0m (96.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,738</span> (96.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24,738\u001b[0m (96.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> (256.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m64\u001b[0m (256.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7035 - loss: 0.6103\n",
      "Epoch 2/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8584 - loss: 0.3371\n",
      "Epoch 3/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8688 - loss: 0.2772\n",
      "Epoch 4/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8701 - loss: 0.2840\n",
      "Epoch 5/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8938 - loss: 0.2503\n",
      "Epoch 6/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8876 - loss: 0.2617\n",
      "Epoch 7/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8983 - loss: 0.2512\n",
      "Epoch 8/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9176 - loss: 0.2151\n",
      "Epoch 9/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9010 - loss: 0.2320\n",
      "Epoch 10/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8969 - loss: 0.2299\n",
      "Epoch 11/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9207 - loss: 0.2156\n",
      "Epoch 12/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9316 - loss: 0.1940\n",
      "Epoch 13/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9208 - loss: 0.1991\n",
      "Epoch 14/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9167 - loss: 0.2195\n",
      "Epoch 15/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9081 - loss: 0.2118\n",
      "Epoch 16/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9230 - loss: 0.2125\n",
      "Epoch 17/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9231 - loss: 0.2074\n",
      "Epoch 18/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9244 - loss: 0.1999\n",
      "Epoch 19/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9289 - loss: 0.1861\n",
      "Epoch 20/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9084 - loss: 0.2171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8678 - loss: 0.3443\n",
      "[0.3670177459716797, 0.8516057729721069]\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array(train_embeddings)\n",
    "x_test = np.array(test_embeddings)\n",
    "y_train = np.array(s_train_df['label'].values)\n",
    "y_test = np.array(s_test_df['label'].values)\n",
    "print('x_train: ', x_train.shape)\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "num_classes = 2\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "# 创建模型\n",
    "x_in = Input(shape=(768,))\n",
    "x_out = Dense(32, activation=\"relu\")(x_in)\n",
    "x_out = BatchNormalization()(x_out)\n",
    "x_out = Dense(num_classes, activation=\"softmax\")(x_out)\n",
    "model = Model(inputs=x_in, outputs=x_out)\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 模型训练以及评估\n",
    "model.fit(x_train, y_train, batch_size=8, epochs=20)\n",
    "model.save('visit_classify.h5')\n",
    "print(model.evaluate(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "db04a0df-c9e4-42df-b8c2-7c7b98f830ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Accuracy score: 0.8516057585825028\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91       740\n",
      "           1       0.58      0.66      0.62       163\n",
      "\n",
      "    accuracy                           0.85       903\n",
      "   macro avg       0.75      0.78      0.76       903\n",
      "weighted avg       0.86      0.85      0.86       903\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "predictions = model.predict(x_test)\n",
    "predictions_labels = np.argmax(predictions, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "print(\"Accuracy score: {}\".format(accuracy_score(predictions_labels, y_test_labels)))\n",
    "print(classification_report(y_test_labels, predictions_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a54f560-3c78-4c27-9cfa-df3cbbb7ed31",
   "metadata": {},
   "source": [
    "模型在测试集上的准确率是85.16%。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e05e4f-58a7-44d3-b7fe-2f12c4cdb40c",
   "metadata": {},
   "source": [
    "#### 3.2.2 SMOTE平衡，提高正例查全率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6c526818-ce84-4308-8ec2-dae4d9aaff90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 使用imlbearn库中上采样方法中的SMOTE接口\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# 定义SMOTE模型\n",
    "x_train = np.array(train_embeddings)\n",
    "x_test = np.array(test_embeddings)\n",
    "y_train = np.array(s_train_df['label'].values)\n",
    "y_test = np.array(s_test_df['label'].values)\n",
    "smo = SMOTE(random_state=42)\n",
    "# 创造出平衡后样本\n",
    "X_balance,y_balance = [],[]\n",
    "X,Y = smo.fit_resample(x_train, np.array(s_train_df['label'].values))\n",
    "X_balance.append(X)\n",
    "y_balance.append(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d9db725f-1e1c-4533-a452-6f93bad30f25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 重新检查平衡程度\n",
    "fig,ax = plt.subplots(figsize=(8,5), dpi=80)\n",
    "sns.countplot(x=y_balance[0])\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'\\n{p.get_height()}', (p.get_x()+0.35, p.get_height()), color='black', size=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ce389aed-3d4c-4112-bdca-48a117367110",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (3472, 768)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_14\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_14\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,608</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_14               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_14 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │          \u001b[38;5;34m24,608\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_14               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │              \u001b[38;5;34m66\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,802</span> (96.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,802\u001b[0m (96.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,738</span> (96.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24,738\u001b[0m (96.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> (256.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m64\u001b[0m (256.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/20\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7504 - loss: 0.5154\n",
      "Epoch 2/20\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8521 - loss: 0.3427\n",
      "Epoch 3/20\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8844 - loss: 0.3075\n",
      "Epoch 4/20\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8776 - loss: 0.3089\n",
      "Epoch 5/20\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8697 - loss: 0.3011\n",
      "Epoch 6/20\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8930 - loss: 0.2754\n",
      "Epoch 7/20\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9048 - loss: 0.2598\n",
      "Epoch 8/20\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8943 - loss: 0.2582\n",
      "Epoch 9/20\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8927 - loss: 0.2527\n",
      "Epoch 10/20\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9048 - loss: 0.2543\n",
      "Epoch 11/20\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9037 - loss: 0.2424\n",
      "Epoch 12/20\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8980 - loss: 0.2577\n",
      "Epoch 13/20\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8997 - loss: 0.2537\n",
      "Epoch 14/20\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9125 - loss: 0.2256\n",
      "Epoch 15/20\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9157 - loss: 0.2178\n",
      "Epoch 16/20\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9125 - loss: 0.2442\n",
      "Epoch 17/20\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9203 - loss: 0.2121\n",
      "Epoch 18/20\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9148 - loss: 0.2154\n",
      "Epoch 19/20\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9233 - loss: 0.2032\n",
      "Epoch 20/20\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9292 - loss: 0.1912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8371 - loss: 0.5158 \n",
      "[0.5039404630661011, 0.8183831572532654]\n"
     ]
    }
   ],
   "source": [
    "x_train_b = X_balance[0]\n",
    "y_train_b = y_balance[0]\n",
    "print('x_train: ', x_train_b.shape)\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "num_classes = 2\n",
    "y_train_b = to_categorical(y_train_b, num_classes)\n",
    "\n",
    "# 创建模型\n",
    "x_in = Input(shape=(768,))\n",
    "x_out = Dense(32, activation=\"relu\")(x_in)\n",
    "x_out = BatchNormalization()(x_out)\n",
    "x_out = Dense(num_classes, activation=\"softmax\")(x_out)\n",
    "model = Model(inputs=x_in, outputs=x_out)\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 模型训练以及评估\n",
    "model.fit(x_train_b, y_train_b, batch_size=8, epochs=20)\n",
    "model.save('balance_visit_classify.h5')\n",
    "print(model.evaluate(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "22096d59-f55a-43ff-adba-4791043aba2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Accuracy score: 0.8183831672203765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.83      0.88       740\n",
      "           1       0.50      0.75      0.60       163\n",
      "\n",
      "    accuracy                           0.82       903\n",
      "   macro avg       0.72      0.79      0.74       903\n",
      "weighted avg       0.86      0.82      0.83       903\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SMOTE后拟合效果\n",
    "predictions = model.predict(x_test)\n",
    "predictions_labels = np.argmax(predictions, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "print(\"Accuracy score: {}\".format(accuracy_score(predictions_labels, y_test_labels)))\n",
    "print(classification_report(y_test_labels, predictions_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a3ffa84a-e157-4efa-abeb-5e15b1f7e705",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "   predicted_label  actual_label                     text\n",
      "0                0             0             三文鱼：“你说谁呢？！”\n",
      "1                1             0  来，看我打开直播，给出致命一击！呀呀呀，跳劈！\n",
      "2                0             0             英国皇室应该可以出面了。\n",
      "3                0             0            谷歌搜索不是抄袭雅虎的吗？\n",
      "4                0             0        要是忍了又没发展出来那不骂得更惨？\n"
     ]
    }
   ],
   "source": [
    "# 使用模型进行预测\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# 将预测结果转换为类别标签\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# 将二进制分类矩阵转换回一维数组\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# 创建一个新的 DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'predicted_label': predicted_labels,\n",
    "    'actual_label': y_test_labels,\n",
    "    'text': s_test_df['text']  # s_test_df测试文本\n",
    "})\n",
    "\n",
    "# 显示结果\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a0b6b9e3-4470-48c8-af92-eedf23c3fd01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>actual_label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>猴王还是有良心的企业家！必须点个赞！“假如小米首月供货不足百万台，大家不用催了，我就去工厂拧...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>联想确实不属于一家中国公司，它是植根中国的买办楷模！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>由此可以看得出来，棒子的胸怀也是美容整出来的。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>而且你们提前一天通知，人家就是想请假也来不及吧，没有竞争的服务就是霸气！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>我倒觉得联想没问题，人家作为一家美国良心公司，当然不是中国公司啦！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>韩国人爱国可是有一套的，为了逃避兵役连国籍都可以放弃。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>默克尔都连任四届了，也没见西媒叫唤。双标、假新闻岂是浪得虚名！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>贱民也能当总统，好民主啊！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>您这背书真厉害，嘴叭叭的就不停，声音大的我耳朵都快聋了。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>这样一个大国，如此厚颜无耻且疑神疑鬼，必定在人类简史上留下重重一笔！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>哦，今天才知道，民主的洪水也泡粮食。哈哈。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>果然，美国就是有大智慧——传说中的大智若愚精神！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>很好，基金就快跌破大关了。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>政坛选举如同上演喜剧，各自演员齐全，热闹非凡，自由选举的编剧导演无与伦比的优秀，小丑骗子演员...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>访日之前，北约秘书长斯托尔滕贝格刚对韩国进行了访问，属于是黄鼠狼串门了。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>特朗普总统还真是做生意的天才，居然想到拿国家做生意。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>高高举起，轻轻落下，几番言语把一件刚刚露出冰山一角的东西又遮掩了过去，高！实在是高！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>民主灯塔国是对的，新西兰只是个异端。宪法第二修正案万岁！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>真是一位好演员，我哭了我还是辣鸡观众，不配看您的作品。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>想不到艰苦朴素的优良传统被美国拿走了，缝缝补补又一年。而我们却提倡消费升级，这个我是不会再坐...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     predicted_label  actual_label  \\\n",
       "11                 1             1   \n",
       "16                 0             1   \n",
       "28                 0             1   \n",
       "32                 1             1   \n",
       "38                 1             1   \n",
       "39                 1             1   \n",
       "41                 1             1   \n",
       "43                 1             1   \n",
       "51                 1             1   \n",
       "54                 1             1   \n",
       "61                 1             1   \n",
       "66                 1             1   \n",
       "68                 1             1   \n",
       "74                 1             1   \n",
       "75                 1             1   \n",
       "82                 1             1   \n",
       "87                 0             1   \n",
       "94                 0             1   \n",
       "110                1             1   \n",
       "113                1             1   \n",
       "\n",
       "                                                  text  \n",
       "11   猴王还是有良心的企业家！必须点个赞！“假如小米首月供货不足百万台，大家不用催了，我就去工厂拧...  \n",
       "16                          联想确实不属于一家中国公司，它是植根中国的买办楷模！  \n",
       "28                             由此可以看得出来，棒子的胸怀也是美容整出来的。  \n",
       "32                而且你们提前一天通知，人家就是想请假也来不及吧，没有竞争的服务就是霸气！  \n",
       "38                   我倒觉得联想没问题，人家作为一家美国良心公司，当然不是中国公司啦！  \n",
       "39                         韩国人爱国可是有一套的，为了逃避兵役连国籍都可以放弃。  \n",
       "41                     默克尔都连任四届了，也没见西媒叫唤。双标、假新闻岂是浪得虚名！  \n",
       "43                                       贱民也能当总统，好民主啊！  \n",
       "51                        您这背书真厉害，嘴叭叭的就不停，声音大的我耳朵都快聋了。  \n",
       "54                  这样一个大国，如此厚颜无耻且疑神疑鬼，必定在人类简史上留下重重一笔！  \n",
       "61                               哦，今天才知道，民主的洪水也泡粮食。哈哈。  \n",
       "66                            果然，美国就是有大智慧——传说中的大智若愚精神！  \n",
       "68                                       很好，基金就快跌破大关了。  \n",
       "74   政坛选举如同上演喜剧，各自演员齐全，热闹非凡，自由选举的编剧导演无与伦比的优秀，小丑骗子演员...  \n",
       "75                访日之前，北约秘书长斯托尔滕贝格刚对韩国进行了访问，属于是黄鼠狼串门了。  \n",
       "82                          特朗普总统还真是做生意的天才，居然想到拿国家做生意。  \n",
       "87          高高举起，轻轻落下，几番言语把一件刚刚露出冰山一角的东西又遮掩了过去，高！实在是高！  \n",
       "94                        民主灯塔国是对的，新西兰只是个异端。宪法第二修正案万岁！  \n",
       "110                        真是一位好演员，我哭了我还是辣鸡观众，不配看您的作品。  \n",
       "113  想不到艰苦朴素的优良传统被美国拿走了，缝缝补补又一年。而我们却提倡消费升级，这个我是不会再坐...  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 显示 results_df 中所有 actual_label 为 1 的行\n",
    "filtered_results_df = results_df[results_df['actual_label'] == 1]\n",
    "\n",
    "# 打印结果\n",
    "filtered_results_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6de134-86ee-42c6-8b45-64e048361c5a",
   "metadata": {},
   "source": [
    "##### 模型效果检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f03bf117-564e-442b-8f92-0cc98fb66794",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 加载模型\n",
    "model = load_model('visit_classify.h5')\n",
    "\n",
    "# 加载tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-chinese\")\n",
    "bert_model = AutoModel.from_pretrained(\"google-bert/bert-base-chinese\")\n",
    "\n",
    "def encode_text(texts):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    # 使用最后一层的hidden states的平均值作为句子的表示\n",
    "    embeddings = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "    return embeddings\n",
    "\n",
    "# 定义预测函数\n",
    "def predict_text(text, model, tokenizer, bert_model):\n",
    "    # 对文本进行编码\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=150)\n",
    "    # 获取BERT模型的输出\n",
    "    outputs = bert_model(**inputs)\n",
    "    # 使用最后一层的hidden states的平均值作为句子的表示\n",
    "    embeddings = outputs.last_hidden_state[:, 0, :].detach().numpy()\n",
    "    # 模型预测\n",
    "    predictions = model.predict(embeddings)\n",
    "    # 将预测结果转换为类别标签\n",
    "    predicted_class = np.argmax(predictions, axis=1)\n",
    "    return predicted_class\n",
    "\n",
    "# 输入文本\n",
    "input_texts = [\"这家菜不错！\", \n",
    "               \"这间球馆太差了！\",\n",
    "               \"贱民也能当总统，好民主啊！\",\n",
    "               \"哦，今天才知道，民主的洪水也泡粮食。真好笑。\"]\n",
    "\n",
    "input_embeddings = encode_text(input_texts)\n",
    "x_input = np.array(input_embeddings)\n",
    "pre_input = model.predict(x_input)\n",
    "input_labels = np.argmax(pre_input, axis=1)\n",
    "input_labels\n",
    "# # 对每个文本进行预测\n",
    "# for text in input_texts:\n",
    "#     predicted_class = predict_text(text, model, tokenizer, bert_model)\n",
    "#     print(f\"文本：'{text}' 预测类别：{'讽刺' if input_labels == 0 else '非讽刺'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "1e13fe11-614a-43fc-962c-8f4b4a3c37db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "文本：'真山真水拍成假山假水，这导演太厉害了。' 预测类别：讽刺\n",
      "文本：'这位李先生笑死我了。' 预测类别：非讽刺\n",
      "文本：'菜品丰富，每道菜都非常美味可口。' 预测类别：非讽刺\n",
      "文本：'真的太厉害了！能让大家吃的都不满意！' 预测类别：讽刺\n",
      "文本：'这个粉我知道，上次我们村闹洪灾就是这个粉把水吸完的！' 预测类别：非讽刺\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 加载模型\n",
    "model = load_model('balance_visit_classify.h5')\n",
    "\n",
    "# 加载tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-chinese\")\n",
    "bert_model = AutoModel.from_pretrained(\"google-bert/bert-base-chinese\")\n",
    "\n",
    "# 定义预测函数\n",
    "def predict_text(text, model, tokenizer, bert_model):\n",
    "    # 对文本进行编码\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=150)\n",
    "    # 获取BERT模型的输出\n",
    "    outputs = bert_model(**inputs)\n",
    "    # 使用最后一层的hidden states的平均值作为句子的表示\n",
    "    embeddings = outputs.last_hidden_state[:, 0, :].detach().numpy()\n",
    "    # 模型预测\n",
    "    predictions = model.predict(embeddings)\n",
    "    # 将预测结果转换为类别标签\n",
    "    predicted_class = np.argmax(predictions, axis=1)\n",
    "    return predicted_class\n",
    "\n",
    "# 输入文本\n",
    "input_texts = [\"真山真水拍成假山假水，这导演太厉害了。\",\"这位李先生笑死我了。\",\"菜品丰富，每道菜都非常美味可口。\",\"真的太厉害了！能让大家吃的都不满意！\",\"这个粉我知道，上次我们村闹洪灾就是这个粉把水吸完的！\"]\n",
    "\n",
    "input_embeddings = encode_text(input_texts)\n",
    "x_input = np.array(input_embeddings)\n",
    "pre_input = model.predict(x_input)\n",
    "input_labels = np.argmax(pre_input, axis=1)\n",
    "input_labels\n",
    "\n",
    "# 对每个文本进行预测\n",
    "for i, text in enumerate(input_texts):\n",
    "    print(f\"文本：'{text}' 预测类别：{'讽刺' if input_labels[i] == 1 else '非讽刺'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2004cb-9e5c-4696-aebe-8efcd6c7c6e7",
   "metadata": {},
   "source": [
    "大部分文本都能判断出是否讽刺，但涉及一定语境的句子（例如上面的第五段文本），模型难以识别。后续进一步添加上下文联合识别。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345c7465-d86c-4a9c-849c-2b3480df564b",
   "metadata": {},
   "source": [
    "### 3.3 利用模型找出原数据集的讽刺评论"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2965a6f6-5fb7-4195-8869-76258a0435e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 重新导入Bert向量\n",
    "embeddings_df = pd.read_csv(\"bert_emb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7aad48a9-1b5e-47c9-a681-5aea6125a126",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problemEB_0</th>\n",
       "      <th>problemEB_1</th>\n",
       "      <th>problemEB_2</th>\n",
       "      <th>problemEB_3</th>\n",
       "      <th>problemEB_4</th>\n",
       "      <th>problemEB_5</th>\n",
       "      <th>problemEB_6</th>\n",
       "      <th>problemEB_7</th>\n",
       "      <th>problemEB_8</th>\n",
       "      <th>problemEB_9</th>\n",
       "      <th>...</th>\n",
       "      <th>problemEB_758</th>\n",
       "      <th>problemEB_759</th>\n",
       "      <th>problemEB_760</th>\n",
       "      <th>problemEB_761</th>\n",
       "      <th>problemEB_762</th>\n",
       "      <th>problemEB_763</th>\n",
       "      <th>problemEB_764</th>\n",
       "      <th>problemEB_765</th>\n",
       "      <th>problemEB_766</th>\n",
       "      <th>problemEB_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002786</td>\n",
       "      <td>0.350907</td>\n",
       "      <td>-0.590879</td>\n",
       "      <td>0.624839</td>\n",
       "      <td>0.275236</td>\n",
       "      <td>-0.998189</td>\n",
       "      <td>0.249843</td>\n",
       "      <td>-1.160770</td>\n",
       "      <td>-0.333895</td>\n",
       "      <td>0.661828</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.536378</td>\n",
       "      <td>0.239979</td>\n",
       "      <td>0.343862</td>\n",
       "      <td>0.967223</td>\n",
       "      <td>0.913974</td>\n",
       "      <td>-0.801003</td>\n",
       "      <td>-0.047445</td>\n",
       "      <td>-0.197605</td>\n",
       "      <td>0.059263</td>\n",
       "      <td>-0.138500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.388467</td>\n",
       "      <td>0.344315</td>\n",
       "      <td>0.032715</td>\n",
       "      <td>-0.823201</td>\n",
       "      <td>0.978599</td>\n",
       "      <td>-1.090205</td>\n",
       "      <td>0.495675</td>\n",
       "      <td>-0.690717</td>\n",
       "      <td>-0.325970</td>\n",
       "      <td>0.588440</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.829643</td>\n",
       "      <td>-0.294156</td>\n",
       "      <td>-0.028544</td>\n",
       "      <td>-1.372434</td>\n",
       "      <td>-0.540188</td>\n",
       "      <td>-0.806019</td>\n",
       "      <td>0.476399</td>\n",
       "      <td>0.238898</td>\n",
       "      <td>-0.232822</td>\n",
       "      <td>-0.024937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.239318</td>\n",
       "      <td>0.292602</td>\n",
       "      <td>0.541064</td>\n",
       "      <td>-0.180603</td>\n",
       "      <td>0.326330</td>\n",
       "      <td>-1.056555</td>\n",
       "      <td>0.003999</td>\n",
       "      <td>-1.555352</td>\n",
       "      <td>0.225033</td>\n",
       "      <td>0.333953</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.635317</td>\n",
       "      <td>0.872438</td>\n",
       "      <td>0.532460</td>\n",
       "      <td>0.822976</td>\n",
       "      <td>0.994111</td>\n",
       "      <td>-1.065691</td>\n",
       "      <td>0.190030</td>\n",
       "      <td>-1.125029</td>\n",
       "      <td>0.076238</td>\n",
       "      <td>0.196769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.463375</td>\n",
       "      <td>0.265843</td>\n",
       "      <td>-0.954373</td>\n",
       "      <td>-0.184800</td>\n",
       "      <td>0.771330</td>\n",
       "      <td>-1.255783</td>\n",
       "      <td>0.268276</td>\n",
       "      <td>-1.316844</td>\n",
       "      <td>-0.101130</td>\n",
       "      <td>0.470056</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.718720</td>\n",
       "      <td>-0.206989</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.192804</td>\n",
       "      <td>1.041080</td>\n",
       "      <td>-0.851206</td>\n",
       "      <td>-0.136673</td>\n",
       "      <td>-0.067548</td>\n",
       "      <td>0.217650</td>\n",
       "      <td>-0.122807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.536140</td>\n",
       "      <td>0.671927</td>\n",
       "      <td>0.256286</td>\n",
       "      <td>0.845530</td>\n",
       "      <td>0.309015</td>\n",
       "      <td>-1.011913</td>\n",
       "      <td>0.090691</td>\n",
       "      <td>-0.755432</td>\n",
       "      <td>-0.736551</td>\n",
       "      <td>0.488083</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.638142</td>\n",
       "      <td>0.317016</td>\n",
       "      <td>0.473254</td>\n",
       "      <td>0.544670</td>\n",
       "      <td>1.111727</td>\n",
       "      <td>-0.678114</td>\n",
       "      <td>-0.265979</td>\n",
       "      <td>-1.327919</td>\n",
       "      <td>0.226817</td>\n",
       "      <td>-0.379921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   problemEB_0  problemEB_1  problemEB_2  problemEB_3  problemEB_4  \\\n",
       "0     0.002786     0.350907    -0.590879     0.624839     0.275236   \n",
       "1    -0.388467     0.344315     0.032715    -0.823201     0.978599   \n",
       "2     0.239318     0.292602     0.541064    -0.180603     0.326330   \n",
       "3     0.463375     0.265843    -0.954373    -0.184800     0.771330   \n",
       "4     0.536140     0.671927     0.256286     0.845530     0.309015   \n",
       "\n",
       "   problemEB_5  problemEB_6  problemEB_7  problemEB_8  problemEB_9  ...  \\\n",
       "0    -0.998189     0.249843    -1.160770    -0.333895     0.661828  ...   \n",
       "1    -1.090205     0.495675    -0.690717    -0.325970     0.588440  ...   \n",
       "2    -1.056555     0.003999    -1.555352     0.225033     0.333953  ...   \n",
       "3    -1.255783     0.268276    -1.316844    -0.101130     0.470056  ...   \n",
       "4    -1.011913     0.090691    -0.755432    -0.736551     0.488083  ...   \n",
       "\n",
       "   problemEB_758  problemEB_759  problemEB_760  problemEB_761  problemEB_762  \\\n",
       "0      -0.536378       0.239979       0.343862       0.967223       0.913974   \n",
       "1      -0.829643      -0.294156      -0.028544      -1.372434      -0.540188   \n",
       "2      -0.635317       0.872438       0.532460       0.822976       0.994111   \n",
       "3      -0.718720      -0.206989       0.382353       0.192804       1.041080   \n",
       "4      -0.638142       0.317016       0.473254       0.544670       1.111727   \n",
       "\n",
       "   problemEB_763  problemEB_764  problemEB_765  problemEB_766  problemEB_767  \n",
       "0      -0.801003      -0.047445      -0.197605       0.059263      -0.138500  \n",
       "1      -0.806019       0.476399       0.238898      -0.232822      -0.024937  \n",
       "2      -1.065691       0.190030      -1.125029       0.076238       0.196769  \n",
       "3      -0.851206      -0.136673      -0.067548       0.217650      -0.122807  \n",
       "4      -0.678114      -0.265979      -1.327919       0.226817      -0.379921  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "aa82b9dc-4f81-4769-b017-a418673e8903",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_df = embeddings_df.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cd7335a0-18ea-4fe4-9a9f-5ef80076739f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00278629,  0.35090706, -0.59087926, ..., -0.19760486,\n",
       "         0.05926282, -0.13850011],\n",
       "       [-0.38846737,  0.34431458,  0.03271492, ...,  0.23889849,\n",
       "        -0.232822  , -0.02493664],\n",
       "       [ 0.23931806,  0.29260227,  0.5410645 , ..., -1.125029  ,\n",
       "         0.07623835,  0.19676909],\n",
       "       ...,\n",
       "       [ 0.55928653,  0.6094477 , -0.98230743, ..., -0.12526947,\n",
       "         0.6154813 , -0.3157287 ],\n",
       "       [-0.08111879,  0.8300608 , -0.02728182, ...,  0.3840966 ,\n",
       "         0.05153142, -0.3311476 ],\n",
       "       [ 0.7358173 ,  0.9331026 , -0.39252228, ..., -0.6822709 ,\n",
       "         0.2088018 ,  0.03047774]], dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9b984919-a34a-45f0-bcaa-8ccde5f3f762",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>很快，好吃，味道足，量大</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>没有送水没有送水没有送水</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>非常快，态度好。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>方便，快捷，味道可口，快递给力</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>菜味道很棒！送餐很及时！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11982</th>\n",
       "      <td>0</td>\n",
       "      <td>以前几乎天天吃，现在调料什么都不放，</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11983</th>\n",
       "      <td>0</td>\n",
       "      <td>昨天订凉皮两份，什么调料都没有放，就放了点麻油，特别难吃，丢了一份，再也不想吃了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11984</th>\n",
       "      <td>0</td>\n",
       "      <td>凉皮太辣,吃不下都</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11985</th>\n",
       "      <td>0</td>\n",
       "      <td>本来迟到了还自己点！！！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11986</th>\n",
       "      <td>0</td>\n",
       "      <td>肉夹馍不错，羊肉泡馍酱肉包很一般。凉面没想象中好吃。送餐倒是很快。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11987 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                    review\n",
       "0          1                              很快，好吃，味道足，量大\n",
       "1          1                              没有送水没有送水没有送水\n",
       "2          1                                  非常快，态度好。\n",
       "3          1                           方便，快捷，味道可口，快递给力\n",
       "4          1                              菜味道很棒！送餐很及时！\n",
       "...      ...                                       ...\n",
       "11982      0                        以前几乎天天吃，现在调料什么都不放，\n",
       "11983      0  昨天订凉皮两份，什么调料都没有放，就放了点麻油，特别难吃，丢了一份，再也不想吃了\n",
       "11984      0                                 凉皮太辣,吃不下都\n",
       "11985      0                              本来迟到了还自己点！！！\n",
       "11986      0         肉夹馍不错，羊肉泡馍酱肉包很一般。凉面没想象中好吃。送餐倒是很快。\n",
       "\n",
       "[11987 rows x 2 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"waimai.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c89e1204-4e9e-42aa-898e-d4fa7f231dad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satire_label</th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>很快，好吃，味道足，量大</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>没有送水没有送水没有送水</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>非常快，态度好。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>方便，快捷，味道可口，快递给力</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>菜味道很棒！送餐很及时！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11982</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>以前几乎天天吃，现在调料什么都不放，</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11983</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>昨天订凉皮两份，什么调料都没有放，就放了点麻油，特别难吃，丢了一份，再也不想吃了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11984</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>凉皮太辣,吃不下都</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11985</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>本来迟到了还自己点！！！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11986</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>肉夹馍不错，羊肉泡馍酱肉包很一般。凉面没想象中好吃。送餐倒是很快。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11987 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       satire_label  emotion_label                                      text\n",
       "0                 1              1                              很快，好吃，味道足，量大\n",
       "1                 0              1                              没有送水没有送水没有送水\n",
       "2                 1              1                                  非常快，态度好。\n",
       "3                 0              1                           方便，快捷，味道可口，快递给力\n",
       "4                 1              1                              菜味道很棒！送餐很及时！\n",
       "...             ...            ...                                       ...\n",
       "11982             0              0                        以前几乎天天吃，现在调料什么都不放，\n",
       "11983             0              0  昨天订凉皮两份，什么调料都没有放，就放了点麻油，特别难吃，丢了一份，再也不想吃了\n",
       "11984             0              0                                 凉皮太辣,吃不下都\n",
       "11985             1              0                              本来迟到了还自己点！！！\n",
       "11986             1              0         肉夹馍不错，羊肉泡馍酱肉包很一般。凉面没想象中好吃。送餐倒是很快。\n",
       "\n",
       "[11987 rows x 3 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "# 加载模型\n",
    "model = load_model('balance_visit_classify.h5')\n",
    "\n",
    "# 使用模型进行预测\n",
    "predictions = model.predict(x_df)\n",
    "\n",
    "# 将预测结果转换为类别标签\n",
    "satire_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# 创建一个新的 DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'satire_label': satire_labels,\n",
    "    'emotion_label': df['label'],\n",
    "    'text': df['review'] \n",
    "})\n",
    "\n",
    "# 显示结果\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "b2b08be0-157e-413e-8427-948da002b720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satire_label</th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11932</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>点的超辣，结果是不辣的，而且等了一个多小时才到。真忍了。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11936</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>快递小哥坚持送到位，表扬一下。,螺狮粉味道太一般。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11938</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>外卖骑士将近两小时送到,而且还要我下去取餐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11941</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>送了两个多小时！大家吃饭我工作，大家开工了，我端一碗臭臭的螺狮粉，想想什么感受吧！快递大哥态...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11950</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>速度满，十一点四十下的单，一点半到的菜叶都是黄的，我也是醉了，送餐员满头大汗，我是心疼了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11953</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>下了单说一个小时之后送，过了一个小时送餐员打电话又说晚15分钟，而且态度不好！味道也一般，跟...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11955</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>味道没店里的好。订单少送一个绿豆沙，发票的单子的价格也是错的，懒得再打电话，送了1个小时20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11958</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>粉很好吃，但是订了卤蛋却没有。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11960</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>粉很好吃，就是配送员找不到位置还一直埋怨，送来时已经坨了！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11961</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>排骨不好吃～还都是色素～量少的可怜～58元的菜啊,只有七块排骨～一点味道没有～肉很干～坑死了...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11964</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>送餐速度太慢了，几百米将近半个小时才送到，油泼面都没法吃了……很不满意</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11966</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>你们的菜品质量已经刷新新的下降高度，店家你们知道吗？这么好的地方美食你们忍心做成这样吗？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11969</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>谢谢！速度很快辛苦了！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11971</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>满三十为啥没优惠了。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11972</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>连双筷子都没有，明明点的葡萄汁结果送来的是酸梅汤，也真是无语了！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11974</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>鸡蛋都坏了，凉菜也洒了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11976</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>外送员很赞，商家能不能仔细看订单啊！点的干拌面送来的是汤面，说了粉汤羊血要多加辣椒送来的一点...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11979</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>羊汤也太次了,哪有放油菜的,服了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11985</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>本来迟到了还自己点！！！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11986</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>肉夹馍不错，羊肉泡馍酱肉包很一般。凉面没想象中好吃。送餐倒是很快。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       satire_label  emotion_label  \\\n",
       "11932             1              0   \n",
       "11936             1              0   \n",
       "11938             1              0   \n",
       "11941             1              0   \n",
       "11950             1              0   \n",
       "11953             1              0   \n",
       "11955             1              0   \n",
       "11958             1              0   \n",
       "11960             1              0   \n",
       "11961             1              0   \n",
       "11964             1              0   \n",
       "11966             1              0   \n",
       "11969             1              0   \n",
       "11971             1              0   \n",
       "11972             1              0   \n",
       "11974             1              0   \n",
       "11976             1              0   \n",
       "11979             1              0   \n",
       "11985             1              0   \n",
       "11986             1              0   \n",
       "\n",
       "                                                    text  \n",
       "11932                       点的超辣，结果是不辣的，而且等了一个多小时才到。真忍了。  \n",
       "11936                          快递小哥坚持送到位，表扬一下。,螺狮粉味道太一般。  \n",
       "11938                              外卖骑士将近两小时送到,而且还要我下去取餐  \n",
       "11941  送了两个多小时！大家吃饭我工作，大家开工了，我端一碗臭臭的螺狮粉，想想什么感受吧！快递大哥态...  \n",
       "11950       速度满，十一点四十下的单，一点半到的菜叶都是黄的，我也是醉了，送餐员满头大汗，我是心疼了  \n",
       "11953  下了单说一个小时之后送，过了一个小时送餐员打电话又说晚15分钟，而且态度不好！味道也一般，跟...  \n",
       "11955  味道没店里的好。订单少送一个绿豆沙，发票的单子的价格也是错的，懒得再打电话，送了1个小时20...  \n",
       "11958                                    粉很好吃，但是订了卤蛋却没有。  \n",
       "11960                      粉很好吃，就是配送员找不到位置还一直埋怨，送来时已经坨了！  \n",
       "11961  排骨不好吃～还都是色素～量少的可怜～58元的菜啊,只有七块排骨～一点味道没有～肉很干～坑死了...  \n",
       "11964                送餐速度太慢了，几百米将近半个小时才送到，油泼面都没法吃了……很不满意  \n",
       "11966       你们的菜品质量已经刷新新的下降高度，店家你们知道吗？这么好的地方美食你们忍心做成这样吗？  \n",
       "11969                                        谢谢！速度很快辛苦了！  \n",
       "11971                                         满三十为啥没优惠了。  \n",
       "11972                   连双筷子都没有，明明点的葡萄汁结果送来的是酸梅汤，也真是无语了！  \n",
       "11974                                        鸡蛋都坏了，凉菜也洒了  \n",
       "11976  外送员很赞，商家能不能仔细看订单啊！点的干拌面送来的是汤面，说了粉汤羊血要多加辣椒送来的一点...  \n",
       "11979                                   羊汤也太次了,哪有放油菜的,服了  \n",
       "11985                                       本来迟到了还自己点！！！  \n",
       "11986                  肉夹馍不错，羊肉泡馍酱肉包很一般。凉面没想象中好吃。送餐倒是很快。  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 显示 results_df 中所有 actual_label 为 1 的行\n",
    "filtered_results_df = results_df[results_df['satire_label'] == 1]\n",
    "\n",
    "# 打印结果\n",
    "filtered_results_df.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e37abb-a7a0-406b-a69f-c165c8657a93",
   "metadata": {},
   "source": [
    "应该判断的是：当emotion和情感分析结果不同时，判断是否讽刺。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "14702201-2532-45d8-8d53-e2cb663f73b6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测了100行\n",
      "预测了200行\n",
      "预测了300行\n",
      "预测了400行\n",
      "预测了500行\n",
      "预测了600行\n",
      "预测了700行\n",
      "预测了800行\n",
      "预测了900行\n",
      "预测了1000行\n",
      "预测了1100行\n",
      "预测了1200行\n",
      "预测了1300行\n",
      "预测了1400行\n",
      "预测了1500行\n",
      "预测了1600行\n",
      "预测了1700行\n",
      "预测了1800行\n",
      "预测了1900行\n",
      "预测了2000行\n",
      "预测了2100行\n",
      "预测了2200行\n",
      "预测了2300行\n",
      "预测了2400行\n",
      "预测了2500行\n",
      "预测了2600行\n",
      "预测了2700行\n",
      "预测了2800行\n",
      "预测了2900行\n",
      "预测了3000行\n",
      "预测了3100行\n",
      "预测了3200行\n",
      "预测了3300行\n",
      "预测了3400行\n",
      "预测了3500行\n",
      "预测了3600行\n",
      "预测了3700行\n",
      "预测了3800行\n",
      "预测了3900行\n",
      "预测了4000行\n",
      "预测了4100行\n",
      "预测了4200行\n",
      "预测了4300行\n",
      "预测了4400行\n",
      "预测了4500行\n",
      "预测了4600行\n",
      "预测了4700行\n",
      "预测了4800行\n",
      "预测了4900行\n",
      "预测了5000行\n",
      "预测了5100行\n",
      "预测了5200行\n",
      "预测了5300行\n",
      "预测了5400行\n",
      "预测了5500行\n",
      "预测了5600行\n",
      "预测了5700行\n",
      "预测了5800行\n",
      "预测了5900行\n",
      "预测了6000行\n",
      "预测了6100行\n",
      "预测了6200行\n",
      "预测了6300行\n",
      "预测了6400行\n",
      "预测了6500行\n",
      "预测了6600行\n",
      "预测了6700行\n",
      "预测了6800行\n",
      "预测了6900行\n",
      "预测了7000行\n",
      "预测了7100行\n",
      "预测了7200行\n",
      "预测了7300行\n",
      "预测了7400行\n",
      "预测了7500行\n",
      "预测了7600行\n",
      "预测了7700行\n",
      "预测了7800行\n",
      "预测了7900行\n",
      "预测了8000行\n",
      "预测了8100行\n",
      "预测了8200行\n",
      "预测了8300行\n",
      "预测了8400行\n",
      "预测了8500行\n",
      "预测了8600行\n",
      "预测了8700行\n",
      "预测了8800行\n",
      "预测了8900行\n",
      "预测了9000行\n",
      "预测了9100行\n",
      "预测了9200行\n",
      "预测了9300行\n",
      "预测了9400行\n",
      "预测了9500行\n",
      "预测了9600行\n",
      "预测了9700行\n",
      "预测了9800行\n",
      "预测了9900行\n",
      "预测了10000行\n",
      "预测了10100行\n",
      "预测了10200行\n",
      "预测了10300行\n",
      "预测了10400行\n",
      "预测了10500行\n",
      "预测了10600行\n",
      "预测了10700行\n",
      "预测了10800行\n",
      "预测了10900行\n",
      "预测了11000行\n",
      "预测了11100行\n",
      "预测了11200行\n",
      "预测了11300行\n",
      "预测了11400行\n",
      "预测了11500行\n",
      "预测了11600行\n",
      "预测了11700行\n",
      "预测了11800行\n",
      "预测了11900行\n",
      "[1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# 加载模型和分词器\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert_emotion_model')\n",
    "utokenizer = AutoTokenizer.from_pretrained('bert_emotion_model')\n",
    "\n",
    "# 定义预测函数\n",
    "def predict(text, model, tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_class = torch.argmax(logits, dim=-1).item()\n",
    "    return predicted_class\n",
    "\n",
    "# 测试数据\n",
    "test_texts = df['review'] \n",
    "\n",
    "# # 对测试数据进行预测\n",
    "# predictions = [predict(text, model, utokenizer) for text in test_texts]\n",
    "# 对测试数据进行预测\n",
    "predictions = []\n",
    "count = 0  # 初始化计数器\n",
    "for text in test_texts:\n",
    "    predictions.append(predict(text, model, utokenizer))\n",
    "    count += 1  # 每次预测后增加计数器\n",
    "    if count % 100 == 0:  # 每1000次预测打印一次\n",
    "        print(f\"预测了{count}行\")\n",
    "\n",
    "# 打印预测结果\n",
    "print(predictions)  # 输出可能是 [1, 0]，具体取决于你的标签编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9c128367-256b-46fa-821c-eb4b940dd439",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satire_label</th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>predict_label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>很快，好吃，味道足，量大</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>没有送水没有送水没有送水</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>非常快，态度好。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>方便，快捷，味道可口，快递给力</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>菜味道很棒！送餐很及时！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11982</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>以前几乎天天吃，现在调料什么都不放，</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11983</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>昨天订凉皮两份，什么调料都没有放，就放了点麻油，特别难吃，丢了一份，再也不想吃了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11984</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>凉皮太辣,吃不下都</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11985</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>本来迟到了还自己点！！！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11986</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>肉夹馍不错，羊肉泡馍酱肉包很一般。凉面没想象中好吃。送餐倒是很快。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11987 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       satire_label  emotion_label  predict_label  \\\n",
       "0                 1              1              1   \n",
       "1                 0              1              0   \n",
       "2                 1              1              1   \n",
       "3                 0              1              1   \n",
       "4                 1              1              1   \n",
       "...             ...            ...            ...   \n",
       "11982             0              0              0   \n",
       "11983             0              0              0   \n",
       "11984             0              0              0   \n",
       "11985             1              0              0   \n",
       "11986             1              0              0   \n",
       "\n",
       "                                           text  \n",
       "0                                  很快，好吃，味道足，量大  \n",
       "1                                  没有送水没有送水没有送水  \n",
       "2                                      非常快，态度好。  \n",
       "3                               方便，快捷，味道可口，快递给力  \n",
       "4                                  菜味道很棒！送餐很及时！  \n",
       "...                                         ...  \n",
       "11982                        以前几乎天天吃，现在调料什么都不放，  \n",
       "11983  昨天订凉皮两份，什么调料都没有放，就放了点麻油，特别难吃，丢了一份，再也不想吃了  \n",
       "11984                                 凉皮太辣,吃不下都  \n",
       "11985                              本来迟到了还自己点！！！  \n",
       "11986         肉夹馍不错，羊肉泡馍酱肉包很一般。凉面没想象中好吃。送餐倒是很快。  \n",
       "\n",
       "[11987 rows x 4 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "# 加载模型\n",
    "model = load_model('balance_visit_classify.h5')\n",
    "\n",
    "# 使用模型进行预测\n",
    "satire = model.predict(x_df)\n",
    "\n",
    "# 将预测结果转换为类别标签\n",
    "satire_labels = np.argmax(satire, axis=1)\n",
    "\n",
    "# 创建一个新的 DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'satire_label': satire_labels,\n",
    "    'emotion_label': df['label'],\n",
    "    'predict_label': predictions,\n",
    "    'text': df['review'] \n",
    "})\n",
    "\n",
    "# 显示结果\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "82fd95ee-07a4-4de5-ba12-32bb09613530",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satire_label</th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>predict_label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>没有送水没有送水没有送水</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>太麻了，青笋有点小，米饭给的也不多，土豆片都碎了，找不到了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>感觉没有在店里的好吃，感谢送餐师傅我们家六楼没电梯还得爬楼梯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>东西还可以，但是没有在店里吃的好吃</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>锅底怎么是13？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11880</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>味道不错，送的时间长了点</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11923</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>就是时间稍微长些</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11960</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>粉很好吃，就是配送员找不到位置还一直埋怨，送来时已经坨了！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11969</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>谢谢！速度很快辛苦了！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11977</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>味道可以试试</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>875 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       satire_label  emotion_label  predict_label  \\\n",
       "1                 0              1              0   \n",
       "44                1              1              0   \n",
       "54                1              1              0   \n",
       "64                0              1              0   \n",
       "65                0              1              0   \n",
       "...             ...            ...            ...   \n",
       "11880             0              0              1   \n",
       "11923             0              0              1   \n",
       "11960             1              0              1   \n",
       "11969             1              0              1   \n",
       "11977             0              0              1   \n",
       "\n",
       "                                 text  \n",
       "1                        没有送水没有送水没有送水  \n",
       "44      太麻了，青笋有点小，米饭给的也不多，土豆片都碎了，找不到了  \n",
       "54     感觉没有在店里的好吃，感谢送餐师傅我们家六楼没电梯还得爬楼梯  \n",
       "64                  东西还可以，但是没有在店里吃的好吃  \n",
       "65                           锅底怎么是13？  \n",
       "...                               ...  \n",
       "11880                    味道不错，送的时间长了点  \n",
       "11923                        就是时间稍微长些  \n",
       "11960   粉很好吃，就是配送员找不到位置还一直埋怨，送来时已经坨了！  \n",
       "11969                     谢谢！速度很快辛苦了！  \n",
       "11977                          味道可以试试  \n",
       "\n",
       "[875 rows x 4 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 找到'predict_label'和'emotion_label'不相等的行\n",
    "mismatched_rows = results_df[results_df['predict_label'] != results_df['emotion_label']]\n",
    "mismatched_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "909c70bc-daac-4b42-b999-f08b1a7e3590",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satire_label</th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>predict_label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>太麻了，青笋有点小，米饭给的也不多，土豆片都碎了，找不到了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>感觉没有在店里的好吃，感谢送餐师傅我们家六楼没电梯还得爬楼梯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>喝了好几年快乐柠檬,第一次喝曲奇奶茶,个人觉得不好喝,本人还是更喜欢茶类冰饮,给配送员赞一个...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>可惜不能更改杯型，又所有订单也不齐全</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>赶上雨最大的时候，外卖小哥很不容易</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11372</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>不错，就是送的太慢了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11448</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>不错，希望品质如初！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11449</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>希望品质如一!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11960</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>粉很好吃，就是配送员找不到位置还一直埋怨，送来时已经坨了！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11969</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>谢谢！速度很快辛苦了！</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       satire_label  emotion_label  predict_label  \\\n",
       "44                1              1              0   \n",
       "54                1              1              0   \n",
       "136               1              1              0   \n",
       "257               1              1              0   \n",
       "304               1              1              0   \n",
       "...             ...            ...            ...   \n",
       "11372             1              0              1   \n",
       "11448             1              0              1   \n",
       "11449             1              0              1   \n",
       "11960             1              0              1   \n",
       "11969             1              0              1   \n",
       "\n",
       "                                                    text  \n",
       "44                         太麻了，青笋有点小，米饭给的也不多，土豆片都碎了，找不到了  \n",
       "54                        感觉没有在店里的好吃，感谢送餐师傅我们家六楼没电梯还得爬楼梯  \n",
       "136    喝了好几年快乐柠檬,第一次喝曲奇奶茶,个人觉得不好喝,本人还是更喜欢茶类冰饮,给配送员赞一个...  \n",
       "257                                   可惜不能更改杯型，又所有订单也不齐全  \n",
       "304                                    赶上雨最大的时候，外卖小哥很不容易  \n",
       "...                                                  ...  \n",
       "11372                                         不错，就是送的太慢了  \n",
       "11448                                         不错，希望品质如初！  \n",
       "11449                                            希望品质如一!  \n",
       "11960                      粉很好吃，就是配送员找不到位置还一直埋怨，送来时已经坨了！  \n",
       "11969                                        谢谢！速度很快辛苦了！  \n",
       "\n",
       "[246 rows x 4 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mismatched_rows[mismatched_rows['satire_label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a73d00fb-bac9-4b27-a2f2-6909c9ae7048",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "判断不一致的样本中，属于讽刺样本的数量是: 246\n"
     ]
    }
   ],
   "source": [
    "# 找到不一致的项中的讽刺项\n",
    "count_satire_label_1 = mismatched_rows[mismatched_rows['satire_label'] == 1].shape[0]\n",
    "print(f\"判断不一致的样本中，属于讽刺样本的数量是: {count_satire_label_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49276fe-fddb-4153-8bd0-05ed1e8bdbfd",
   "metadata": {},
   "source": [
    "通过情绪分析和讽刺分析联合分析，找出具有争议的评论。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a260b75-c4ac-439c-9b74-ed65cbeaf363",
   "metadata": {},
   "source": [
    "## 四、Stage3-订单语境+上下文分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db31db4e-ebeb-4f79-9213-fa735e0d562e",
   "metadata": {},
   "source": [
    "结合上下文，面向话题进行讽刺识别；尝试对BERT进行微调，以适应\n",
    "\n",
    "参考文献：Topic-Oriented Sarcasm Detection: New Task, New Dataset and New Method(Bin Liang, Zijie Lin, Bing Qin, Ruifeng Xu, 2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76bf085-bb29-4a3f-9c0b-a0502cbfcaaa",
   "metadata": {},
   "source": [
    "### 4.1 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db85d73d-9c7d-4f24-9c5c-1fda39a9d1fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chennxx\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import argparse\n",
    "import time\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from transformers import BatchEncoding, BertForSequenceClassification, BertTokenizer, get_cosine_schedule_with_warmup\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a6fa63d-f67c-4968-87f4-3d6ce9ad76d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将原始数据（raw_data）转换成一个PyTorch的DataLoader对象\n",
    "def get_dataloader(raw_data, tokenizer, batch_size=32, max_len=256, split='train', sample:int=None):\n",
    "    def collate(batch):\n",
    "        return {'guid': torch.stack([batch[i][0] for i in range(len(batch))], dim=0),\n",
    "                'inputs': BatchEncoding({\n",
    "                    'input_ids': torch.stack([batch[i][1] for i in range(len(batch))], dim=0),\n",
    "                    'token_type_ids': torch.stack([batch[i][2] for i in range(len(batch))], dim=0),\n",
    "                    'attention_mask': torch.stack([batch[i][3] for i in range(len(batch))], dim=0),\n",
    "                }),\n",
    "                'labels': torch.stack([batch[i][-1] for i in range(len(batch))], dim=0)\n",
    "                }\n",
    "\n",
    "    guids = []\n",
    "    all_text = []\n",
    "    labels = []\n",
    "    for i, example in enumerate(raw_data):\n",
    "        guids.append(i)\n",
    "        text_a = example['topic']\n",
    "        text_b = example['text']\n",
    "        all_text.append(text_b + '[SEP]' + text_a)\n",
    "        labels.append(int(example['label']))\n",
    "    guids = torch.tensor(guids, dtype=torch.long)\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    dataset = tokenizer(all_text[:sample] if sample else all_text,\n",
    "                        max_length=max_len,\n",
    "                        return_tensors='pt',\n",
    "                        padding='max_length',\n",
    "                        truncation=True\n",
    "                        )\n",
    "    dataset = TensorDataset(guids[:sample] if sample else guids,\n",
    "                            dataset['input_ids'],\n",
    "                            dataset['token_type_ids'],\n",
    "                            dataset['attention_mask'],\n",
    "                            labels[:sample] if sample else labels)\n",
    "\n",
    "    print(\"%s size: %d\" % (split, len(dataset)))\n",
    "\n",
    "    if split == 'train':\n",
    "        return DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            collate_fn=collate,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        return DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=batch_size,\n",
    "            collate_fn=collate,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f13818b-76ed-41df-8a0e-4fcc37d012e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 模型的训练和评估\n",
    "def run_msd(args, seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    device = torch.device(\"cpu\")  # 指定设备为CPU\n",
    "\n",
    "    model_save_path = os.path.join(args['save_path'], 'best_model.std')\n",
    "\n",
    "    # 加载数据\n",
    "    with open(op.join(args['data_path'], 'train.json'), 'r', encoding='utf-8') as f:\n",
    "        train_data = json.load(f)\n",
    "    with open(op.join(args['data_path'], 'dev.json'), 'r', encoding='utf-8') as f:\n",
    "        valid_data = json.load(f)\n",
    "    with open(op.join(args['data_path'], 'test.json'), 'r', encoding='utf-8') as f:\n",
    "        test_data = json.load(f)\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained('google-bert/bert-base-chinese')\n",
    "    model = BertForSequenceClassification.from_pretrained('google-bert/bert-base-chinese')\n",
    "    model = model.to(device)  # 将模型发送到CPU\n",
    "\n",
    "    train_dataloader = get_dataloader(train_data, tokenizer, batch_size=args['batch_size'], max_len=args['max_length'], split='train', sample=args['num_sample'])\n",
    "    valid_dataloader = get_dataloader(valid_data, tokenizer, batch_size=args['batch_size'], max_len=args['max_length'], split='valid')\n",
    "    test_dataloader = get_dataloader(test_data, tokenizer, batch_size=args['batch_size'], max_len=args['max_length'], split='test')\n",
    "\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay': 0.0}\n",
    "    ]\n",
    "    optimizer = optim.Adam(optimizer_grouped_parameters, lr=args['lr'], weight_decay=args['weight_decay'])\n",
    "    total_steps = len(train_dataloader) * args['epoch']\n",
    "    scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=0.1 * total_steps,\n",
    "                                                num_training_steps=total_steps)\n",
    "\n",
    "    # 训练\n",
    "    best_f1 = 0.0\n",
    "    for epoch in tqdm(range(args['epoch']), desc='Training'):\n",
    "        tic = time.time()\n",
    "\n",
    "        train_loss = 0.0\n",
    "        train_size = 0\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        for batch in tqdm(train_dataloader, desc='Epoch: %s' % epoch):\n",
    "            batch_inputs = {k: v.to(device) for k, v in batch['inputs'].items()}\n",
    "            labels = batch['labels'].to(device)\n",
    "            logits = model(**batch_inputs)['logits']\n",
    "            loss = loss_func(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "\n",
    "            batch_size = len(labels)\n",
    "            train_loss += loss.item() * batch_size\n",
    "            train_size += batch_size\n",
    "\n",
    "        train_loss = train_loss / train_size\n",
    "\n",
    "        # 验证\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(valid_dataloader):\n",
    "                batch_inputs = {k: v.to(device) for k, v in batch['inputs'].items()}\n",
    "                labels = batch['labels']\n",
    "                logits = model(**batch_inputs)['logits']\n",
    "                y_pred.append(torch.argmax(logits, dim=-1).cpu().numpy())\n",
    "                y_true.append(labels.cpu().numpy())\n",
    "\n",
    "        y_pred = np.concatenate(y_pred, axis=0)\n",
    "        y_true = np.concatenate(y_true, axis=0)\n",
    "        results = classification_report(y_pred=y_pred, y_true=y_true)\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        p = precision_score(y_true, y_pred)\n",
    "        r = recall_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        macro_p = precision_score(y_true, y_pred, average='macro')\n",
    "        macro_r = recall_score(y_true, y_pred, average='macro')\n",
    "        macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "        print('-- EPOCH %s: train_loss = %.4f, time: %s s\\n'\n",
    "              '-- EPOCH %s: valid results: acc=%.4f, p=%.4f, r=%.4f, f1=%.4f\\n'\n",
    "              '--                   macro: acc=%.4f, p=%.4f, r=%.4f, f1=%.4f' % (\n",
    "                  epoch, train_loss, time.time() - tic, epoch, acc, p, r, f1, acc, macro_p, macro_r, macro_f1))\n",
    "        print(results)\n",
    "        if best_f1 < f1:\n",
    "            best_f1 = f1\n",
    "            print('-- EPOCH %s: new best model! save to %s' % (epoch, model_save_path))\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "    # 测试\n",
    "    model.load_state_dict(torch.load(model_save_path))\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader):\n",
    "            batch_inputs = {k: v.to(device) for k, v in batch['inputs'].items()}\n",
    "            labels = batch['labels']\n",
    "            logits = model(**batch_inputs)['logits']\n",
    "            y_pred.append(torch.argmax(logits, dim=-1).cpu().numpy())\n",
    "            y_true.append(labels.cpu().numpy())\n",
    "\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    results = classification_report(y_pred=y_pred, y_true=y_true)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    p = precision_score(y_true, y_pred)\n",
    "    r = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    macro_p = precision_score(y_true, y_pred, average='macro')\n",
    "    macro_r = recall_score(y_true, y_pred, average='macro')\n",
    "    macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    print('-- test results: acc=%.4f, p=%.4f, r=%.4f, f1=%.4f\\n'\n",
    "          '--        macro: acc=%.4f, p=%.4f, r=%.4f, f1=%.4f' % (acc, p, r, f1, acc, macro_p, macro_r, macro_f1))\n",
    "    print(results)\n",
    "\n",
    "    return {'accuracy': acc,\n",
    "            'precision': p,\n",
    "            'recall': r,\n",
    "            'f1': f1,\n",
    "            'macro precision': macro_p,\n",
    "            'macro recall': macro_r,\n",
    "            'macro f1': macro_f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81d765da-f790-45e6-8a81-e7b0b6ef4d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 2925\n",
      "valid size: 973\n",
      "test size: 973\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a447460275845b59ecb4f6c3f955bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cb3b873830341cb9ba4d34af703427b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 0:   0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0cf58475ed4dc9b77436da7123eb6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- EPOCH 0: train_loss = 0.6912, time: 3868.4555852413177 s\n",
      "-- EPOCH 0: valid results: acc=0.6341, p=0.7605, r=0.6932, f1=0.7253\n",
      "--                   macro: acc=0.6341, p=0.5873, r=0.5958, f1=0.5888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.50      0.45       295\n",
      "           1       0.76      0.69      0.73       678\n",
      "\n",
      "    accuracy                           0.63       973\n",
      "   macro avg       0.59      0.60      0.59       973\n",
      "weighted avg       0.66      0.63      0.64       973\n",
      "\n",
      "-- EPOCH 0: new best model! save to ./12-topic/save/bert/best_model.std\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9cac8b4adde40a2b31d22168b37a5c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 1:   0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c774213cb7f742be9acffae0c2b59675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- EPOCH 1: train_loss = 0.6089, time: 3695.739688396454 s\n",
      "-- EPOCH 1: valid results: acc=0.6927, p=0.8427, r=0.6873, f1=0.7571\n",
      "--                   macro: acc=0.6927, p=0.6690, r=0.6962, f1=0.6695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.71      0.58       295\n",
      "           1       0.84      0.69      0.76       678\n",
      "\n",
      "    accuracy                           0.69       973\n",
      "   macro avg       0.67      0.70      0.67       973\n",
      "weighted avg       0.74      0.69      0.70       973\n",
      "\n",
      "-- EPOCH 1: new best model! save to ./12-topic/save/bert/best_model.std\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "858622f9bd204735b3d168e27a7fcda7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 2:   0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3743d369669844ca9ab916a46dcbbc14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- EPOCH 2: train_loss = 0.4775, time: 3671.495871782303 s\n",
      "-- EPOCH 2: valid results: acc=0.6937, p=0.8506, r=0.6799, f1=0.7557\n",
      "--                   macro: acc=0.6937, p=0.6735, r=0.7027, f1=0.6726\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.73      0.59       295\n",
      "           1       0.85      0.68      0.76       678\n",
      "\n",
      "    accuracy                           0.69       973\n",
      "   macro avg       0.67      0.70      0.67       973\n",
      "weighted avg       0.74      0.69      0.71       973\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "726e02f391434f37ab09577bc0c843e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 3:   0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02192a740f304a9391b8cf26f3d4d05f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- EPOCH 3: train_loss = 0.3210, time: 3669.560477733612 s\n",
      "-- EPOCH 3: valid results: acc=0.7040, p=0.8272, r=0.7271, f1=0.7739\n",
      "--                   macro: acc=0.7040, p=0.6682, r=0.6890, f1=0.6727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.65      0.57       295\n",
      "           1       0.83      0.73      0.77       678\n",
      "\n",
      "    accuracy                           0.70       973\n",
      "   macro avg       0.67      0.69      0.67       973\n",
      "weighted avg       0.73      0.70      0.71       973\n",
      "\n",
      "-- EPOCH 3: new best model! save to ./12-topic/save/bert/best_model.std\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e3331ffef8248faa3166bf18a407c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 4:   0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0c233203d040d3a5274c4711f66437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- EPOCH 4: train_loss = 0.2066, time: 3674.1471524238586 s\n",
      "-- EPOCH 4: valid results: acc=0.7040, p=0.8533, r=0.6947, f1=0.7659\n",
      "--                   macro: acc=0.7040, p=0.6808, r=0.7101, f1=0.6818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.73      0.60       295\n",
      "           1       0.85      0.69      0.77       678\n",
      "\n",
      "    accuracy                           0.70       973\n",
      "   macro avg       0.68      0.71      0.68       973\n",
      "weighted avg       0.75      0.70      0.71       973\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa91c66c62944d9a21c1af0af4050c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 5:   0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c78afec1054927843f218e7ac3ba2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- EPOCH 5: train_loss = 0.1459, time: 3671.5300636291504 s\n",
      "-- EPOCH 5: valid results: acc=0.6999, p=0.8362, r=0.7080, f1=0.7668\n",
      "--                   macro: acc=0.6999, p=0.6700, r=0.6947, f1=0.6730\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.68      0.58       295\n",
      "           1       0.84      0.71      0.77       678\n",
      "\n",
      "    accuracy                           0.70       973\n",
      "   macro avg       0.67      0.69      0.67       973\n",
      "weighted avg       0.74      0.70      0.71       973\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb14f32cb2984a1ca37dcd035071d99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- test results: acc=0.6948, p=0.7753, r=0.7368, f1=0.7556\n",
      "--        macro: acc=0.6948, p=0.6724, r=0.6784, f1=0.6746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.62      0.59       350\n",
      "           1       0.78      0.74      0.76       623\n",
      "\n",
      "    accuracy                           0.69       973\n",
      "   macro avg       0.67      0.68      0.67       973\n",
      "weighted avg       0.70      0.69      0.70       973\n",
      "\n",
      "{'accuracy': 0.6947584789311408, 'precision': 0.7753378378378378, 'recall': 0.7367576243980738, 'f1': 0.7555555555555555, 'macro precision': 0.672445821806058, 'macro recall': 0.6783788121990368, 'macro f1': 0.6746314029487763}\n"
     ]
    }
   ],
   "source": [
    "# 模型参数\n",
    "args = {\n",
    "    'epoch': 6,\n",
    "    'batch_size': 32,\n",
    "    'max_length': 256,\n",
    "    'lr': 2e-5,\n",
    "    'weight_decay': 2e-3,\n",
    "    'num_sample': None,\n",
    "    'seed': 42,\n",
    "    'seeds': [1001, 1002, 1003, 1004, 1005],\n",
    "    'gpu_id': 0,\n",
    "    'data_path': './12-topic/data/',\n",
    "    'save_path': './12-topic/save/bert/'\n",
    "}\n",
    "\n",
    "# 运行模型\n",
    "results = run_msd(args, seed=42)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358a435d-0cd3-4247-a8e9-7913514aed37",
   "metadata": {},
   "source": [
    "### 4.2 测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e67d3f59-8e3b-42b1-bbfd-b360cf382fb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "# 指定模型保存的路径\n",
    "model_path = './12-topic/save/bert/best_model.std'\n",
    "\n",
    "# 加载模型\n",
    "model = BertForSequenceClassification.from_pretrained('google-bert/bert-base-chinese')\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "model.eval()  # 设置为评估模式\n",
    "\n",
    "# 加载分词器\n",
    "tokenizer = BertTokenizer.from_pretrained('google-bert/bert-base-chinese')\n",
    "\n",
    "# 定义一个函数来进行预测\n",
    "def predict(text_a, text_b):\n",
    "    # 将文本组合成一个字符串，因为训练时是将text_b和text_a拼接在一起的\n",
    "    input_text = text_b + '[SEP]' + text_a\n",
    "\n",
    "    # 使用分词器对输入文本进行编码\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        input_text,\n",
    "        add_special_tokens=True,\n",
    "        return_token_type_ids=True,\n",
    "        max_length=256,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    # 获取输入ID和注意力掩码\n",
    "    input_ids = inputs['input_ids'].tolist()[0]\n",
    "    attention_mask = inputs['attention_mask'].tolist()[0]\n",
    "\n",
    "    # 将输入数据转换为模型需要的格式\n",
    "    inputs = {\n",
    "        'input_ids': torch.tensor([input_ids]),\n",
    "        'attention_mask': torch.tensor([attention_mask])\n",
    "    }\n",
    "\n",
    "    # 进行预测\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # 获取预测结果\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # 根据预测结果返回相应的文本\n",
    "    return \"是\" if predictions == 1 else \"不是\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e1988de9-3173-4d00-b28d-c41118d41a83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“这个粉我知道，上次我们村闹洪灾就是这个粉把水吸完的！”【是】对“顾客在外卖平台上购买商品。”【的讽刺】\n"
     ]
    }
   ],
   "source": [
    "# 使用模型进行预测\n",
    "text_a = \"顾客在外卖平台上购买商品。\"\n",
    "text_b = \"这个粉我知道，上次我们村闹洪灾就是这个粉把水吸完的！\"\n",
    "prediction = predict(text_a, text_b)\n",
    "print(f\"“{text_b}”【{prediction}】对“{text_a}”【的讽刺】\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4e02b789-b13c-48b8-a627-fe8c78bc50c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“菜做的不好吃”【不是】对“顾客在外卖平台上购买商品。”【的讽刺】\n"
     ]
    }
   ],
   "source": [
    "# 使用模型进行预测\n",
    "text_a = \"顾客在外卖平台上购买商品。\"\n",
    "text_b = \"菜做的不好吃\"\n",
    "prediction = predict(text_a, text_b)\n",
    "print(f\"“{text_b}”【{prediction}】对“{text_a}”【的讽刺】\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0cac57-b858-4a39-9a88-3c7dbcedb99d",
   "metadata": {},
   "source": [
    "能够对相应的上下文文本做出讽刺检验，对上述讽刺检验做了良好的补充。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
